{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "get_ipython().ast_node_interactivity = 'all'\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2614acf7db0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 23\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Supp code and exampels](https://github.com/joosthub/PyTorchNLPBookm) \n",
    "Perface > using code example: \"\"\n",
    "\n",
    "> “ Natural Language Processing with PyTorch by Delip Rao and Brian McMahan (O’Reilly). Copyright 2019, Delip Rao and Brian McMahan, 978-1-491-97823-8.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One bot / Binary encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1-1. Generating a “collapsed” one-hot or binary representation using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD4CAYAAADM6gxlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAATR0lEQVR4nO3df7DVdZ3H8deLHxWZv6kU/IGCmbYqpKD9gCBXXSWUmsR+sLs1zZC7JUKj7rQ6xWzR2LrZ5DRtsbljVjrDD7fE8kerKUihAgKiKbMKq/wYZ1iTUEn58d4/vp9LB7jn3C+X+73f85HnY+bM/f4495zX/d7ved3v/ZzvOccRIQBAPvrUHQAAsG8obgDIDMUNAJmhuAEgMxQ3AGSmX9V3sG3Tc5y2UqMBg0bXHWG/bN2wsO4I+yXn7Z/7ts9d/4Enutk6jrgBIDMUNwBkhuIGgMxQ3ACQGYobADJDcQNAZihuAMgMxQ0AmaG4ASAzFDcAZIbiBoDMUNwAkBmKGwAyQ3EDQGYobgDIDMUNAJmhuAEgMxQ3AGSG4gaAzFDcAJAZihsAMkNxA0BmKG4AyAzFDQCZobgBIDMUNwBkhuIGgMxQ3ACQmW4Vt+3zejoIAKCc7h5x39yjKQAApfVrtsL2nc1WSTqymjgAgK40LW5JoyVNlvTKHsstaVRliQAALbUq7sWSXouIh/ZcYfuZ6iIBAFppWtwRcWGLdWOqiQMA6AqnAwJAZihuAMgMxQ0AmSlV3LYH2D656jAAgK51Wdy2J0haLumeND+8xTneAICKlTninqHivO2XJSkilksaUlUgAEBrZYp7e0RsrjwJAKCUVi/A6bDK9mck9bV9kqSpkn5XbSwAQDNljrivkPQ+Sa9Luk3SZknTKswEAGihyyPuiHhN0rXpAgCoWZmzSn5j+7CG+cNt31tpKgBAU2WGSgZGxMsdMxHxR0nvqiwRAKClMsW90/ZxHTO2j5cU1UUCALRS5qySayU9bLvj7V3HSJpSXSQAQCtlnpy8x/b7JZ2j4kMUpkfEpsqTAQA6VeaIW5LeKumldP1TbSsiFlQXCwDQTJmzSr4taZGKIZOr0+WqinN16bpv3agx4z+liZMvrztKt+Se/4Lzx+rJVQv09FMP65qrv1R3nH3G9q9P7tu+HfKXeXJyoqSTI2J8RExIl4srztV1qIvO0w9v/GbdMbot5/x9+vTRTd+bqY9NmKzTzhinyy6bqFNOOanuWPuE7V+fnLe91B75yxT3c5L6Vx1kX501/DQdesjBdcfotpzzjxo5Qs8+u1Zr1jyvbdu2afbsX+riCRfUHWufsP3rk/O2l9ojf5kx7tckLbd9v4qXvUuSImJqZanQ1gYNPkovrNuwa37d+o0aNXJEjYkOLGx/lDnivlPSN1S8sdTShktTtqfYXmJ7yY9vvX3/U6Kt2N5rWQSn9vcWtj/KnA74E9sDJB0XEc+UudGImCVpliRt2/Qce9SbzPp1G3XsMYN2zR8z+Ght3PhijYkOLGx/8Ak42GePLVmuYcNO0JAhx6p///6aNOkSzb/rvrpjHTDY/ujuJ+CcUFmikq7++vX67Bena+3z63TuxMmaNz+v973KOf+OHTt05bTr9Otf3aZVKx/U3Lnz9dRTq+uOtU/Y/vXJedtL7ZHfXY2N2X4kIs62/XhEjEjLVkbE6WXugKGSeg0YNLruCPtl64aFdUfYLzlv/9y3fe76Dzxx7yczEj4BBwAy091PwLmyylAAgObKHHGPj4jdPgHH9qWS5lSWCgDQVJkj7q+WXAYA6AVNj7htXyjpIkmDbd/UsOoQSdurDgYA6FyroZINkpZIuli7v1Jyi6TpVYYCADTXtLgjYoWkFbZvi4htvZgJANBCmScnR9meIen4dH1Liog4scpgAIDOlSnum1UMjSyVtKPaOACArpQp7s0RcXflSQAApZQp7t/avkHSHdr9/biXVZYKANBUmeI+O309q2FZSPpoz8cBAHSlzPtxj+uNIACAcsq8H/e7bd9s++40f6rtL1QfDQDQmTIveb9F0r2SOj5yY7WkaRXlAQB0oUxxD4yI2ZJ2SlJEbBenBQJAbcoU96u2j1TxhKRsn6PirV0BADUoc1bJV1R80vtQ24skvVPSJytNBQBoqsxZJctsf0TSySpe7v4M710CAPVpOlRie6Tto6Rd49pnSpop6Tu2j+ilfACAPbQa4/6RpDckyfYYSddLulXF+Pas6qMBADrTaqikb0S8lKYvkzQrIuZJmmd7eeXJAACdanXE3dd2R7GfK+mBhnVlntQEAFSgVQHfLukh25skbZW0UJJsDxOnAwJAbVp9As5M2/dLOlrSfRERaVUfSVf0RjgAwN5aDnlExOJOlq2uLg4AoCtlXjkJAGgjFDcAZIbiBoDMUNwAkBmKGwAyQ3EDQGYobgDIDMUNAJmhuAEgMxQ3AGSG4gaAzFDcAJAZihsAMkNxA0BmKG4AyAzFDQCZobgBIDMUNwBkhuIGgMxQ3ACQGYobADJDcQNAZihuAMiMI6LSO+j3lsHV3gFa2rphYd0RgFoMGDS67gj7Zfsb691sHUfcAJAZihsAMkNxA0BmKG4AyAzFDQCZobgBIDMUNwBkhuIGgMxQ3ACQGYobADJDcQNAZihuAMgMxQ0AmaG4ASAzFDcAZIbiBoDMUNwAkBmKGwAyQ3EDQGYobgDIDMUNAJmhuAEgMxQ3AGSG4gaAzFDcAJAZihsAMkNxA0BmWha37UNsD+1k+enVRQIAtNK0uG1PkvS0pHm2n7Q9smH1LVUHAwB0rtUR9z9LOjMihkv6vKSf2v5EWueqgwEAOtevxbq+EbFRkiLiUdvjJN1l+xhJ0SvpAAB7aXXEvaVxfDuV+FhJl0h6X8W5AABNtDri/gftMSQSEVts/42kSZWmAgA01bS4I2JFk+XbJP28skQAgJY4jxsAMkNxA0BmShW37QG2T646DACga10Wt+0JkpZLuifND7d9Z8W5AABNlDniniFplKSXJSkilksaUlUgAEBrZYp7e0RsrjwJAKCUVudxd1hl+zOS+to+SdJUSb+rNhYAoJkyR9xXqHil5OuSbpO0WdK0CjMBAFro8og7Il6TdG26AABqVuaskt/YPqxh/nDb91aaCgDQVJmhkoER8XLHTET8UdK7KksEAGipTHHvtH1cx4zt48XbugJAbcqcVXKtpIdtP5Tmx0iaUl0kAEArZZ6cvMf2+yWdo+JtXqdHxKbKkwEAOlXmiFuS3irppXT9U20rIhZUFwsA0EyZs0q+LWmRiiGTq9PlqopzlXLB+WP15KoFevqph3XN1V+qO84+yTm7JF33rRs1ZvynNHHy5XVH6Zac8+ecXco/v1T/47fMk5MTJZ0cEeMjYkK6XFxxri716dNHN31vpj42YbJOO2OcLrtsok455aS6Y5WSc/YOEy86Tz+88Zt1x+i2nPPnnF3KP387PH7LFPdzkvpXHWRfjRo5Qs8+u1Zr1jyvbdu2afbsX+riCRfUHauUnLN3OGv4aTr0kIPrjtFtOefPObuUf/52ePyWGeN+TdJy2/ereNm7JCkiplaWqoRBg4/SC+s27Jpft36jRo0cUWOi8nLODhzo2uHxW6a470yX0mxPUTpl0H0PVZ8+B3UjWpf3sdeyiDxOL885O3Cga4fHb5nTAX9ie4Ck4yLimTI3GhGzJM2SpH5vGVzJT7R+3UYde8ygXfPHDD5aGze+WMVd9bicswMHunZ4/Gb7CTiPLVmuYcNO0JAhx6p///6aNOkSzb/rvrpjlZJzduBA1w6P3+5+As4JlSUqaceOHbpy2nX69a9u06qVD2ru3Pl66qnVdccqJefsHa7++vX67Bena+3z63TuxMmaNz+v9x3LOX/O2aX887fD49ddjc3YfiQizrb9eESMSMtWRsTpZe6gqqESlLN1w8K6IwC1GDBodN0R9sv2N9bvPZie8Ak4AJCZ7n4CzpVVhgIANFfmiHt8ROz2CTi2L5U0p7JUAICmyhxxf7XkMgBAL2h6xG37QkkXSRps+6aGVYdI2l51MABA51oNlWyQtETSxZKWNizfIml6laEAAM01Le6IWCFphe3bImJbL2YCALRQ5snJUbZnSDo+Xd+SIiJOrDIYAKBzZYr7ZhVDI0sl7ag2DgCgK2WKe3NE3F15EgBAKWWK+7e2b5B0h3Z/P+5llaUCADRVprjPTl/PalgWkj7a83EAAF0p837c43ojCACgnDLvx/1u2zfbvjvNn2r7C9VHAwB0psxL3m+RdK+kjo98WC1pWkV5AABdKFPcAyNitqSdkhQR28VpgQBQmzLF/artI1U8ISnb56h4a1cAQA3KnFXyFRWf8j7U9iJJ75T0yUpTAQCaKnNWyTLbH5F0soqXuz/De5cAQH2aDpXYHmn7KGnXuPaZkmZK+o7tI3opHwBgD63GuH8k6Q1Jsj1G0vWSblUxvj2r+mgAgM60GirpGxEvpenLJM2KiHmS5tleXnkyAECnWh1x97XdUeznSnqgYV2ZJzUBABVoVcC3S3rI9iZJWyUtlCTbw8TpgABQm1afgDPT9v2SjpZ0X0REWtVH0hW9EQ4AsLeWQx4RsbiTZauriwMA6EqZV04CANoIxQ0AmaG4ASAzFDcAZIbiBoDMUNwAkBmKGwAyQ3EDQGYobgDIDMUNAJmhuAEgMxQ3AGSG4gaAzFDcAJAZihsAMkNxA0BmKG4AyAzFDQCZobgBIDMUNwBkhuIGgMxQ3ACQGYobADJDcQNAZhwRdWfYL7anRMSsunN0F/nrlXP+nLNL5N8fb4Yj7il1B9hP5K9Xzvlzzi6Rv9veDMUNAAcUihsAMvNmKO5sx8gS8tcr5/w5Z5fI323ZPzkJAAeaN8MRNwAcUChuAMgMxX2Asj3E9qq6c1TF9lTbf7C93vb307LLbf9d3dnKaMj/8334nl/bPixd/rHKfGXZfiV9HWR7bpr+XMfvpN00brvGzO2GMe5eZrtvROxoNt+LOYZIuisi/qq377s32H5a0oWSPiLprIj4cs2R9klH/ohY07CsX0RsL/G9Q9Qmv1vbr0TEO/ZY9jm16e+knbZdK1kdcdv+he2ltp+0PSUte8X2TNsrbC+2/e42zfgvth+R9IFO5r9ie1W6TEvfc43tqWn6u7YfSNPn2v5ZD8XtZ/sntlfanmv77ba/ZvuxlGWWbaf7fdD2t20/anu17dFp+RDbC20vS5cPpuVj0/fMtf207Z833Fan99FTbP9Q0omS7pR0eMPyGbavStNDbd+TflcLbb83Lb805Vphe0FP5upOftub0za6T9Ktex6t2r7L9tg0vdb2QEnXSxpqe7ntG2r4EfbS7D882+Nt/972QNvnp+lltufYfkdnt1Wxxm03pyNz2u6/sD3f9hrbX06P28dT7xyRrtfpftXjIiKbi6Qj0tcBklZJOlJSSJqQlv+rpOvaNOOkhuvsmpd0pqQnJB0k6R2SnpQ0QtI5kuak6yyU9Kik/pK+LumLPZBzSMrxoTT/n5Ku6siflv20Yds+KOk7afoiSf+dpt8u6W1p+iRJS9L0WEmbJR2j4gDh95I+3LiN9ryPHv49rJU0UNLnJH0/LZsh6ao0fb+kk9L02ZIeSNNPSBqcpg+rcT/qyD9D0lJJA9LyXT9Pmr9L0tg9vmeIpFV1Pg4a8r3SsL+tavwZJH087duHp9wLJB2UrvNPkr5WQ97GnHtm/h9JB0t6Z9q3L0/rvitpWqv9qqcv/ZSXqbY/nqaPVVEUb6jYeaViBz+vjmANOsu4Q9K8hus0zn9Y0n9FxKuSZPsOSaMl/bukM20fLOl1ScsknZXWTe2hrC9ExKI0/bN0u2tsX6OikI9Q8YdkfrrOHenrUhU7tVT8Mfm+7eHp53pPw+0/GhHr0s+1PH3Pw5LGtbiPyqUjuQ9KmtNwsP/W9HWRpFtsz9Zfft663RkRW+sO0cPGqdifz4+IP9n+mKRTJS1Kv5O3qPhj305+GxFbJG2xvVl/2WefkHR6F/tVj8qmuNO/g38t6QMR8ZrtByW9TdK2SH/eVBRHbT9Ti4x/jt3HsRvnOx0miIhtttdK+ryk30laqWJnHyrpDz0Uec8nOELSD1SMP75ge0bK3+H19LVxO0+X9KKkM1QcWf+5k+vv+h7bb+viPnpDH0kvR8TwPVdExOW2z5Y0XtJy28Mj4v96Od+eXm2Y3q7dhzh7e9v1lOdUDAe9R9ISFY+D30TEp2tN1Vrj/ryzYX6nisdD0/2qp+U0xn2opD+mQnyviqGEdtOdjAskTUzjywfpL/8+dqy7Kn1dKOlyScsb/lDtr+NsfyBNf1rF0bAkbUpHD58scRuHStoYETsl/a2kvl1cv6No9uU+elRE/EnFfxaXSpILZ6TpoRHxSER8TdImFf81tZO1kobb7mP7WEmjOrnOFhX/0rez/5X0CRXj9u+TtFjSh2wPk6T0eHhPqxuoSLe3Xav9qqflVNz3qDhiWynpGyp+0e1mnzNGxDJJt6gYw35E0o8j4vG0eqGkoyX9PiJeVHE0u7Cz2+mmP0j6+5T3CBXDM/+h4l+/X0h6rMRt/CDdxmIVR0+vtrpyRLzcjfuowmclfcH2ChVDNZek5TfYfiI9KbVA0oqa8jWzSNIaFdvv31QMoe0m/YewKD3J2hZPTnYmIp5R8XuYI+kQFePIt6f9cbGkap7Ya51p17aT1J1t12y/6lGcDggAmcnpiBsAIIobALJDcQNAZihuAMgMxQ0AmaG4ASAzFDcAZOb/Absx4oTTdF/gAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    " \n",
    "sentence1 = 'Time flies flies like an arrow.'\n",
    "sentence2 = 'Fruit flies like a banana.'\n",
    "corpus = [sentence1, sentence2]\n",
    "vocab = ['an', 'arrow', 'banana', 'flies', 'fruit', 'like', 'time']\n",
    "#note here a, an are treated as one word, so only an is shwon\n",
    "one_hot_vectorizer = CountVectorizer(binary=True)\n",
    "one_hot = one_hot_vectorizer.fit_transform(corpus).toarray()\n",
    "one_hot\n",
    "sns.heatmap(one_hot, annot=True,\n",
    "            cbar=False, xticklabels=vocab, # cbar is for the heat value illustartion\n",
    "            yticklabels=['Sentence 1', 'Sentence 2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF representation\n",
    "Example 1-2. Generating a TF-IDF representation using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    " \n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus).toarray()\n",
    "sns.heatmap(tfidf, annot=True, cbar=False, xticklabels=vocab,\n",
    "            yticklabels= ['Sentence 1', 'Sentence 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install pytorch torchvision -c pytorch\n",
    "\n",
    "def p(t=''):\n",
    "    print('-------'+t+'-------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    \"\"\"summarise properties of a tensor x\n",
    "\n",
    "    Args:\n",
    "        x (tensor): \n",
    "    \"\"\"\n",
    "    print(\"Type: {}\".format(x.type()))\n",
    "    print(\"Shape/size: {}\".format(x.shape))\n",
    "    print(\"Values: \\n{}\".format(x))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.Tensor(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random normal dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.5866, 0.0962, 0.1946],\n",
      "        [0.3136, 0.0838, 0.3909]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[ 0.2589,  0.4765, -0.0993],\n",
      "        [-0.8002, -0.0610, -0.3848]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.rand(2, 3))   # uniform random\n",
    "describe(torch.randn(2, 3))  # random normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2, 3],  \n",
    "                 [4, 5, 6]])\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensfor from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.DoubleTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.9093, 0.7515, 0.5657],\n",
      "        [0.5321, 0.7644, 0.4786]], dtype=torch.float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "npy = np.random.rand(2, 3)\n",
    "describe(torch.from_numpy(npy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2, 3],  \n",
    "                    [4, 5, 6]])\n",
    "describe(x)\n",
    "\n",
    "x = x.long()\n",
    "describe(x)\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], \n",
    "                 [4, 5, 6]], dtype=torch.int64)\n",
    "describe(x)\n",
    "\n",
    "x = x.float() \n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randn, add, arange, view/reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------randn-------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5208, -0.1943,  0.2444],\n",
       "        [-0.1555, -0.2432, -0.8521]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------add-------\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-1.0416, -0.3887,  0.4888],\n",
      "        [-0.3111, -0.4865, -1.7041]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-1.0416, -0.3887,  0.4888],\n",
      "        [-0.3111, -0.4865, -1.7041]])\n",
      "\n",
      "-------arange-------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------view/reshape-------\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "-------sum-------\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3])\n",
      "Values: \n",
      "tensor([3, 5, 7])\n",
      "\n",
      "-------transpose-------\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p('randn')\n",
    "x = torch.randn(2, 3)\n",
    "x\n",
    "\n",
    "p('add')\n",
    "describe(torch.add(x, x))\n",
    "describe(x + x)\n",
    "\n",
    "p('arange')\n",
    "x = torch.arange(6)\n",
    "x\n",
    "\n",
    "p('view/reshape')\n",
    "\n",
    "x = x.view(2, 3)\n",
    "describe(x)\n",
    "\n",
    "p('sum')\n",
    "describe(torch.sum(x, dim=0))\n",
    "\n",
    "p('transpose')\n",
    "\n",
    "describe(torch.transpose(x, 0, 1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing and indexing a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([1, 2])\n",
      "Values: \n",
      "tensor([[0, 1]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).view(2, 3)\n",
    "describe(x)\n",
    "\n",
    "describe(x[:1, :2]) # row 0, first two cols\n",
    "\n",
    "describe(x[0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex indexing: noncontiguous indexing of a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[0, 2],\n",
      "        [3, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# indices = torch.LongTensor([0, 2]) \n",
    "indices = torch.tensor([0,2])\n",
    "describe(torch.index_select(x, dim=1, index=indices)) # 0, 2th col only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### particular row + col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------particular row col elements-------\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2])\n",
      "Values: \n",
      "tensor([0, 4])\n",
      "\n",
      "-------cat based rows-------\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([4, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "-------stack-------\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 2, 3])\n",
      "Values: \n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x\n",
    "p()\n",
    "row_indices = torch.arange(2).long()\n",
    "row_indices\n",
    "p()\n",
    "col_indices = torch.LongTensor([0, 1])\n",
    "col_indices\n",
    "p('particular row col elements')\n",
    "describe(x[row_indices, col_indices]) # row0,col0 +  row1,col1\n",
    "p('cat based rows')\n",
    "describe(torch.cat([x, x], dim=0))\n",
    "p('stack') # stack another depth, depth: 2, row: 2, col: 2\n",
    "describe(torch.stack([x, x]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear algebra: add, multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.ones(3, 2)\n",
    "x2\n",
    "x2[:, 1] += 1 # all row, col 1\n",
    "describe(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mm, type must be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[ 3.,  6.],\n",
      "        [12., 24.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.arange(6).view(2, 3).float()\n",
    "describe(x1)\n",
    "describe(x2)\n",
    "\n",
    "describe(torch.mm(x1, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and Computational Graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tensors for gradient bookkeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "describe(x)\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requires_grad   \n",
    "\n",
    "\"When you create a tensor with requires_grad=True, you are requiring PyTorch to manage **bookkeeping** information that computes gradients. \n",
    "First, PyTorch will keep track of the values of the **forward pass**. Then, at the end of the computations, a single **scalar** is used to compute a backward pass. The **backward pass** is initiated by using the backward() method on a tensor resulting from the evaluation of a loss function. The backward pass computes a gradient value for a tensor object that participated in the forward pass.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[21., 21.],\n",
      "        [21., 21.]], grad_fn=<AddBackward0>)\n",
      "\n",
      "False\n",
      "--------------\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      "21.0\n",
      "\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "y = (x + 2) * (x + 5) + 3\n",
    "describe(y)\n",
    "print(x.grad is None)\n",
    "\n",
    "p()\n",
    "\n",
    "z = y.mean()\n",
    "describe(z)\n",
    "z.backward()\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the gradient is a value that represents the **slope** of a function output with respect to the **function input**\n",
    "**Optimizers** use the .grad variable to **update** the values of the **parameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Tensors\n",
    "- To use a GPU, you need to first allocate the tensor on the GPU’s memory\n",
    "- Before it is run on CPU.\n",
    "- The CUDA API was created by **NVIDIA** and is limited to use on only **NVIDIA GPUs**\n",
    "\n",
    "Transfering the tensor from the CPU to the GPU while maintaining its underlying type. The preferred method in PyTorch is to be device agnostic and write code that works whether it’s on the GPU or the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (torch.cuda.is_available())\n",
    "\n",
    "# preferred method: device agnostic tensor instantiation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.cuda.FloatTensor\n",
      "Shape/size: torch.Size([3, 3])\n",
      "Values: \n",
      "tensor([[0.9864, 0.5348, 0.2743],\n",
      "        [0.2985, 0.3224, 0.7795],\n",
      "        [0.5672, 0.4135, 0.9058]], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 3).to(device)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixing CUDA tensors with CPU-bound tensors\n",
    "\n",
    "it is **expensive** to move data back and forth from the GPU. Therefore, the typical procedure involves doing many of the **parallelizable** computations on the GPU and then transferring just the **final result** back to the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "y = torch.rand(3, 3)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert to same device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1606, 1.0611, 0.8188],\n",
       "        [0.4594, 0.7113, 0.9905],\n",
       "        [0.8951, 0.5917, 1.8479]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_device = torch.device(\"cpu\")\n",
    "y = y.to(cpu_device)\n",
    "x = x.to(cpu_device)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More torch API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (UN)SQUEEZE\n",
    "- UNSQUEEZE: Returns a new tensor with a dimension of size one **inserted** at the specified position.\n",
    "- Returns a tensor with all the dimensions of input of size 1 **removed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(3, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAND\n",
    "Returns a tensor filled with random numbers from a uniform distribution on the interval **[0, 1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .normal_()\n",
    "convert to normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expand()\n",
    "making copies of existance ones and expand horizontally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['snow', 'white', 'and', 'the', 'seven', 'degrees', '#makeamoviecold', '@midnight', ':-)']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tweet = u\"Snow White and the Seven Degrees \\\n",
    "    #MakeAMovieCold@midnight:-)\"\n",
    "tokenizer = TweetTokenizer()\n",
    "print(tokenizer.tokenize(tweet.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams\n",
    "sliding window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-grams are fixed-length (n) consecutive token sequences occurring in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mary', ',', \"n't\"], [',', \"n't\", 'slap'], [\"n't\", 'slap', 'green'], ['slap', 'green', 'witch'], ['green', 'witch', '.']]\n"
     ]
    }
   ],
   "source": [
    "def n_grams(text, n):\n",
    "    '''\n",
    "    takes tokens or text, returns a list of n-grams\n",
    "    '''\n",
    "    return [text[i:i+n] for i in range(len(text)-n+1)]\n",
    "\n",
    "cleaned = ['mary', ',', \"n't\", 'slap', 'green', 'witch', '.']\n",
    "print(n_grams(cleaned, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmas are root forms of words. Go -> went, goes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process tweets example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "import numpy as np # Library for linear algebra and math utils\n",
    "\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    '''\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    '''\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    #tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                                reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "            word not in string.punctuation):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorizing Words: POS Tagging\n",
    "part-of-speech (POS) tagging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activiation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(x) = \\frac{1}{1 + e^{-x}} $$ \n",
    "\n",
    "[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.arange(-5., 5., 0.1)\n",
    "y = torch.sigmoid(x)\n",
    "plt.plot(x.numpy(), y.numpy())\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vanishing/exploding gradient\n",
    "the sigmoid function saturates (i.e., produces\n",
    "extreme valued outputs) very quickly and for a majority of the inputs. This can\n",
    "become a problem because it can lead to the gradients becoming either zero or\n",
    "diverging to an overflowing floating-point value. These phenomena are also\n",
    "known as vanishing gradient problem and exploding gradient problem\n",
    "\n",
    "As a consequence, it is rare to see sigmoid units used in neural\n",
    "networks other than at the **output**, where the squashing property allows one to\n",
    "interpret outputs as **probabilities**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(x) = \\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}} $$ \n",
    "\n",
    "[-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maps the set of real values from (–∞, +∞) to\n",
    "the range [-1, +1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "x = torch.arange(-5., 5., 0.1)\n",
    "y = torch.tanh(x)\n",
    "plt.plot(x.numpy(), y.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rectified linear unit  \n",
    "clipping the negative values to zero,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(x) = max(0, x) $$ \n",
    "\n",
    "[0, +inf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clipping effect of ReLU that helps with the **vanishing gradient** problem can\n",
    "also become an issue, where over time certain outputs in the network can simply\n",
    "become **zero and never revive again**. This is called the “dying ReLU” problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "relu = torch.nn.ReLU()\n",
    "x = torch.arange(-5.,5., 0.1)\n",
    "y = relu(x)\n",
    "plt.plot(x.numpy(),y.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To mitigate that effect, variants such as the **Leaky ReLU** and **Parametric ReLU**\n",
    "(PReLU) activation functions have proposed, where the **leak** coefficient a is a\n",
    "**learned** parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(x) = max(x, ax) $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prelu = torch.nn.PReLU(num_parameters=1)\n",
    "x = torch.arange(-5., 5., 0.1)\n",
    "y = prelu(x)\n",
    "plt.plot(x.numpy(), y.detach().numpy()) # since y requires .grad so detach it to type cast numpy andavoid error\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/softmax.png)  \n",
    "[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4676, -0.8147, -0.5850]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6148, 0.1706, 0.2146]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "x_input = torch.randn(1, 3)\n",
    "y_output = softmax(x_input)\n",
    "x_input\n",
    "y_output\n",
    "torch.sum(y_output, dim=1) # sum to one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/mse.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3464, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "outputs = torch.randn(3, 5, requires_grad=True)\n",
    "targets = torch.randn(3, 5)\n",
    "loss = mse_loss(outputs, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/ccel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\#note  \n",
    "compute how **different** two **distributions** are.  \n",
    "We want the probability of the\n",
    "**correct** class to be **close to 1**, whereas the **other** classes have a probability **close\n",
    "to 0**. ***Log(1) = 0***\n",
    "Product = sum of log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3654, -0.6839, -1.2567,  0.6865, -0.1485],\n",
       "        [ 1.6060, -1.1797,  0.6773, -0.0960, -0.3345],\n",
       "        [ 0.5175, -0.5598, -0.3623, -0.0477,  0.8693]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7233, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "outputs = torch.randn(3, 5, requires_grad=True)\n",
    "targets = torch.tensor([1, 0, 3], dtype=torch.int64)\n",
    "loss = ce_loss(outputs, targets)\n",
    "outputs\n",
    "targets\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For above, a vector of random values is first used to simulate network\n",
    "output. Then, the ground truth vector, called targets, is created as a vector of\n",
    "integers because PyTorch’s implementation of CrossEntropyLoss() assumes\n",
    "that each input has one particular **class**, and each class has a unique **index**. This\n",
    "is why targets has **three** elements: an index representing the **correct class** for\n",
    "each **input**. From this assumption, it performs the computationally more efficient\n",
    "operation of indexing into the model output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## why use e in the formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There is a limit to how small or how large a number can be.\n",
    "2. If input negative -> log gives exponentially small number, if positive, exponentially large number.\n",
    "3. Network’s output is assumed to be the vector just prior to applying the softmax\n",
    "function\n",
    "4. The log function is the inverse of the exponential function,\n",
    "and log(exp(x)) is just equal to x.\n",
    "\n",
    "**Conclusion**  \n",
    "mathematical simplifications are made assuming the **exponential**\n",
    "function that is the **core** of the softmax function and the **log** function that is used\n",
    "in the cross-entropy computations in order to be more numerically **stable** and\n",
    "**avoid** really **small** or really **large** numbers (log property)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3914],\n",
       "        [0.2337],\n",
       "        [0.5652],\n",
       "        [0.6740]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3914],\n",
      "        [0.2337],\n",
      "        [0.5652],\n",
      "        [0.6740]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7239, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bce_loss = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "probabilities = sigmoid(torch.randn(4, 1, requires_grad=True))\n",
    "targets = torch.tensor([1, 0, 1, 0], dtype=torch.float32).reshape(4, 1)\n",
    "probabilities\n",
    "targets\n",
    "loss = bce_loss(probabilities, targets)\n",
    "print(probabilities)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning requires the following: a **model**, a\n",
    "**loss** function, **training** data, and an **optimization** algorithm. The training data for\n",
    "supervised learning is pairs of observations and targets; the model computes\n",
    "predictions from the observations, and the loss measures the error of the\n",
    "predictions as compared to the targets. The goal of the training is to use the\n",
    "8\n",
    "gradient-based optimization algorithm to adjust the model’s parameters so that\n",
    "the losses are as low as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimiser\n",
    "\n",
    "While the model produces predictions and the loss function measures\n",
    "the error between predictions and targets, the optimizer **updates** the **weights** of\n",
    "the model using the **error signal**. In its simplest form, there is a single\n",
    "hyperparameter that controls the update behavior of the optimizer. This\n",
    "hyperparameter, called a learning rate, controls how much impact the error\n",
    "signal has on updating the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. any **bookkeeping** information, such as gradients, currently stored inside the model (perceptron) object is **cleared** with a function named zero_grad().\n",
    "2. make **prediction**: the model computes outputs (y_pred) given the input data (x_data).\n",
    "3. the **loss** is computed by comparing model outputs (y_pred) to intended targets (y_target).  \n",
    "The PyTorch loss object (**criterion**) has a function named backward() that iteratively propagates the loss backward through the computational graph and notifies each parameter of its gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Example\n",
    "\n",
    "https://github.com/joosthub/PyTorchNLPBook/blob/master/chapters/chapter_3/Chapter-3-Diving-Deep-into-Supervised-Training.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    \"\"\" A Perceptron is one Linear layer \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): size of the input features\n",
    "        \"\"\"\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        \"\"\"The forward pass of the MLP\n",
    "\n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, 1)\n",
    "        \"\"\"\n",
    "        return torch.sigmoid(self.fc1(x_in))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "input_dim = 2\n",
    "\n",
    "batch_size = 1000\n",
    "n_epochs = 12\n",
    "n_batches = 5\n",
    "\n",
    "seed = 1337\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "perceptron = Perceptron(input_dim=input_dim)\n",
    "optimizer = optim.Adam(params=perceptron.parameters(), lr=lr)\n",
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "losses = []\n",
    "\n",
    "x_data_static, y_truth_static = get_toy_data(batch_size)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "visualize_results(perceptron, x_data_static, y_truth_static, ax=ax, title='Initial Model State')\n",
    "plt.axis('off')\n",
    "#plt.savefig('initial.png')\n",
    "\n",
    "change = 1.0\n",
    "last = 10.0\n",
    "epsilon = 1e-3\n",
    "epoch = 0\n",
    "while change > epsilon or epoch < n_epochs or last > 0.3:\n",
    "#for epoch in range(n_epochs):\n",
    "    for _ in range(n_batches):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        x_data, y_target = get_toy_data(batch_size)\n",
    "        y_pred = perceptron(x_data).squeeze()\n",
    "        loss = bce_loss(y_pred, y_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        loss_value = loss.item()\n",
    "        losses.append(loss_value)\n",
    "\n",
    "        change = abs(last - loss_value)\n",
    "        last = loss_value\n",
    "               \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "    visualize_results(perceptron, x_data_static, y_truth_static, ax=ax, epoch=epoch, \n",
    "                      title=f\"{loss_value}; {change}\")\n",
    "    plt.axis('off')\n",
    "    epoch += 1\n",
    "    #plt.savefig('epoch{}_toylearning.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab, vectoriser, dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Vocabulary** coordinates the **integer-to-token mappings** that\n",
    "we discussed in “Observation and Target Encoding”. We use a Vocabulary both\n",
    "for mapping the text tokens to integers and for mapping the class labels to\n",
    "integers. Next, the **Vectorizer** encapsulates the **vocabularies** and is responsible\n",
    "for ingesting string data, like a review’s text, and **converting** it to numerical\n",
    "**vectors** that will be used in the training routine. We use the final assisting class,\n",
    "PyTorch’s **DataLoader**, to group and **collate** the individual vectorized data\n",
    "points into **minibatches**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Yelp Review Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2015, Yelp held a contest in which it asked participants to predict the rating of\n",
    "a restaurant given its review. Zhang, Zhao, and Lecun (2015) simplified the\n",
    "dataset by converting the 1- and 2-star ratings into a “negative” sentiment class\n",
    "and the 3- and 4-star ratings into a “positive” sentiment class, and split it into\n",
    "560,000 training samples and 38,000 testing samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use a “light” version of the\n",
    "dataset, which is derived by selecting 10% of the training samples as the full\n",
    "dataset. This has two consequences. First, using a small dataset makes the\n",
    "training–testing loop fast, so we can experiment quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this smaller subset, we split the dataset into three partitions: one for\n",
    "training, one for validation, and one for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training, validation, and testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the subset by rating to create new train, val, and test splits\n",
    "by_rating = collections.defaultdict(list)\n",
    "for _, row in review_subset.iterrows():\n",
    "    by_rating[row.rating].append(row.to_dict())\n",
    "# Create split data\n",
    "final_list = []\n",
    "np.random.seed(args.seed)\n",
    "for _, item_list in sorted(by_rating.items()):\n",
    "    np.random.shuffle(item_libst)\n",
    "    n_total = len(item_list)\n",
    "    n_train = int(args.train_proportion * n_total)\n",
    "    n_val = int(args.val_proportion * n_total)\n",
    "    n_test = int(args.test_proportion * n_total)\n",
    "    # Give data point a split attribute\n",
    "    for item in item_list[:n_train]:\n",
    "    item['split'] = 'train'\n",
    "    for item in item_list[n_train:n_train+n_val]:\n",
    "    item['split'] = 'val'\n",
    "    for item in item_list[n_train+n_val:n_train+n_val+n_test]:\n",
    "    item['split'] = 'test'\n",
    "    # Add to final list\n",
    "    final_list.extend(item_list)\n",
    "    final_reviews = pd.DataFrame(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimally cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    # adding whitespace around punctuation symbols: 'a!b' => 'a ! b'\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    # removing extraneous symbols that aren’t punctuation for all the splits\n",
    "    # E.g. @ will be removed\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text\n",
    "final_reviews.review = final_reviews.review.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from text to vectorized minibatch is to map each **token** to\n",
    "a **numerical** version of itself.\n",
    "- The standard methodology is to have a **bijection—a**\n",
    "mapping that can be reversed—between the tokens and integers. In Python, this is simply **two** **dictionaries**.\n",
    "- The Vocabulary class not only manages this\n",
    "bijection—allowing the user to **add new tokens** and have the i**ndex\n",
    "autoincrement**—but also handles a special token called UNK, which stands for **“unknown**.\n",
    "- we will even explicitly **restrict** **infrequent** tokens from our Vocabulary so that there are **UNK** tokens in our **training** routine\n",
    "------------   \n",
    "- add_token() is called to add new tokens to the Vocabulary, -\n",
    "- lookup_token() when retrieving the index for a token, and \n",
    "- lookup_index() when retrieving the token corresponding to a specific index.\n",
    "------------\n",
    "The Vocabulary class **maintains** token to integer mapping needed\n",
    "for the rest of the machine learning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
    "            unk_token (str): the UNK token to add into the Vocabulary\n",
    "        \"\"\"\n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        \n",
    "        self.unk_index = -1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token) \n",
    "        \n",
    "        \n",
    "    def to_serializable(self):\n",
    "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
    "        return {'token_to_idx': self._token_to_idx, \n",
    "                'add_unk': self._add_unk, \n",
    "                'unk_token': self._unk_token}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "    \n",
    "    def add_many(self, tokens):\n",
    "        \"\"\"Add a list of tokens into the Vocabulary\n",
    "        \n",
    "        Args:\n",
    "            tokens (list): a list of string tokens\n",
    "        Returns:\n",
    "            indices (list): a list of indices corresponding to the tokens\n",
    "        \"\"\"\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- second stage of going from a **text** dataset to a **vectorized** minibatch is to **iterate** through the tokens of an input data point and convert each token to its integer form\n",
    "- utilizes Python’s @classmethod decorator for the method **from_dataframe()** to **indicate** an **entry** point to **instantiating** the Vectorizer\n",
    "- from_dataframe() iterates over the rows of a Pandas DataFrame with two goals.\n",
    "  - first goal is to **count** the **frequency** of all tokens present in\n",
    "the dataset.\n",
    "  - The second goal is to **create** a **Vocabulary** that only uses tokens that **are** as **frequent** as a provided keyword argument to the method, cutoff. Effectively, this method is finding **all words** that occur **at least cutoff times** and **adding** them to the **Vocabulary**.\n",
    "  - Because the UNK token is also added to the Vocabulary, any **words** that are **not added** will have the **unk_index** when the Vocabulary’s **lookup_token**() method is called\n",
    "\n",
    "-----------------\n",
    "The method **vectorize**() encapsulates the core functionality of the\n",
    "Vectorizer.\n",
    "- It takes as an argument a string representing a review and returns a **vectorized representation** of the review.\n",
    "- one-hot representation is used below.\n",
    "- limitations.\n",
    "  - sparse—the number of unique words in the review will always be far less than the number of unique words in the Vocabulary\n",
    "  - discards the order in which the words appeared in the review (the “bag of words” approach).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
    "    def __init__(self, review_vocab, rating_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            review_vocab (Vocabulary): maps words to integers\n",
    "            rating_vocab (Vocabulary): maps class labels to integers\n",
    "        \"\"\"\n",
    "        self.review_vocab = review_vocab\n",
    "        self.rating_vocab = rating_vocab\n",
    "\n",
    "    def vectorize(self, review):\n",
    "        \"\"\"Create a collapsed one-hit vector for the review\n",
    "        \n",
    "        Args:\n",
    "            review (str): the review \n",
    "        Returns:\n",
    "            one_hot (np.ndarray): the collapsed one-hot encoding \n",
    "        \"\"\"\n",
    "        one_hot = np.zeros(len(self.review_vocab), dtype=np.float32)\n",
    "        \n",
    "        for token in review.split(\" \"):\n",
    "            if token not in string.punctuation:\n",
    "                one_hot[self.review_vocab.lookup_token(token)] = 1\n",
    "\n",
    "        return one_hot\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, review_df, cutoff=25):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            review_df (pandas.DataFrame): the review dataset\n",
    "            cutoff (int): the parameter for frequency-based filtering\n",
    "        Returns:\n",
    "            an instance of the ReviewVectorizer\n",
    "        \"\"\"\n",
    "        review_vocab = Vocabulary(add_unk=True)\n",
    "        rating_vocab = Vocabulary(add_unk=False)\n",
    "        \n",
    "        # Add ratings\n",
    "        for rating in sorted(set(review_df.rating)):\n",
    "            rating_vocab.add_token(rating)\n",
    "\n",
    "        # Add top words if count > provided count\n",
    "        word_counts = Counter()\n",
    "        for review in review_df.review:\n",
    "            for word in review.split(\" \"):\n",
    "                if word not in string.punctuation:\n",
    "                    word_counts[word] += 1\n",
    "               \n",
    "        for word, count in word_counts.items():\n",
    "            if count > cutoff:\n",
    "                review_vocab.add_token(word)\n",
    "\n",
    "        return cls(review_vocab, rating_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\"Instantiate a ReviewVectorizer from a serializable dictionary\n",
    "        \n",
    "        Args:\n",
    "            contents (dict): the serializable dictionary\n",
    "        Returns:\n",
    "            an instance of the ReviewVectorizer class\n",
    "        \"\"\"\n",
    "        review_vocab = Vocabulary.from_serializable(contents['review_vocab'])\n",
    "        rating_vocab =  Vocabulary.from_serializable(contents['rating_vocab'])\n",
    "\n",
    "        return cls(review_vocab=review_vocab, rating_vocab=rating_vocab)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        \"\"\"Create the serializable dictionary for caching\n",
    "        \n",
    "        Returns:\n",
    "            contents (dict): the serializable dictionary\n",
    "        \"\"\"\n",
    "        return {'review_vocab': self.review_vocab.to_serializable(),\n",
    "                'rating_vocab': self.rating_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A PyTorch Dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final stage of the text-to-vectorized-minibatch pipeline is to actually **group** the vectorized data points\n",
    "- we wrap the DataLoader in a **generate_batches**() function, which is a generator to conveniently **switch** the data between the CPU and the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, review_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            review_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (ReviewVectorizer): vectorizer instantiated from dataset\n",
    "        \"\"\"\n",
    "        self.review_df = review_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        self.train_df = self.review_df[self.review_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.review_df[self.review_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.review_df[self.review_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, review_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            review_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of ReviewDataset\n",
    "        \"\"\"\n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        train_review_df = review_df[review_df.split=='train']\n",
    "        return cls(review_df, ReviewVectorizer.from_dataframe(train_review_df))\n",
    "    \n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, review_csv, vectorizer_filepath):\n",
    "        \"\"\"Load dataset and the corresponding vectorizer. \n",
    "        Used in the case in the vectorizer has been cached for re-use\n",
    "        \n",
    "        Args:\n",
    "            review_csv (str): location of the dataset\n",
    "            vectorizer_filepath (str): location of the saved vectorizer\n",
    "        Returns:\n",
    "            an instance of ReviewDataset\n",
    "        \"\"\"\n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(review_df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        \"\"\"a static method for loading the vectorizer from file\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
    "        Returns:\n",
    "            an instance of ReviewVectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return ReviewVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        \"\"\"saves the vectorizer to disk using json\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location to save the vectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \n",
    "        \n",
    "        Args:\n",
    "            split (str): one of \"train\", \"val\", or \"test\"\n",
    "        \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        review_vector = \\\n",
    "            self._vectorizer.vectorize(row.review)\n",
    "\n",
    "        rating_index = \\\n",
    "            self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
    "\n",
    "        return {'x_data': review_vector,\n",
    "                'y_target': rating_index}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size  \n",
    "    \n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- numerical stability issues with applying a sigmoid and then using this loss function.\n",
    "- Solution: use **BCEWithLogitsLoss**(), To use  this loss function, the output should not have the sigmoid function applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewClassifier(nn.Module):\n",
    "    \"\"\" a simple perceptron-based classifier \"\"\"\n",
    "    def __init__(self, num_features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        num_features (int): the size of the input feature vector\n",
    "        \"\"\"\n",
    "        super(ReviewClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=num_features,\n",
    "        out_features=1)\n",
    "    def forward(self, x_in, apply_sigmoid=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        Args:\n",
    "        x_in (torch.Tensor): an input data tensor\n",
    "        x_in.shape should be (batch, num_features)\n",
    "        apply_sigmoid (bool): a flag for the sigmoid activation\n",
    "        should be false if used with the cross-entropy losses\n",
    "        Returns:\n",
    "        the resulting tensor. tensor.shape should be (batch,).\n",
    "        \"\"\"\n",
    "        y_out = self.fc1(x_in).squeeze()\n",
    "        if apply_sigmoid:\n",
    "            y_out = F.sigmoid(y_out)\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## args - hyperparam & program options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    frequency_cutoff=25,\n",
    "    model_state_file='model.pth',\n",
    "    review_csv='data/yelp/reviews_with_splits_lite.csv',\n",
    "    save_dir='model_storage/ch3/yelp/',\n",
    "    vectorizer_file='vectorizer.json',\n",
    "    # No model hyperparameters\n",
    "    # Training hyperparameters\n",
    "    batch_size=128,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=100,\n",
    "    seed=1337,\n",
    "    # Runtime options omitted for space\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper: Initial/update train state, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1}\n",
    "train_state = make_train_state(args)\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "# dataset and vectorizer\n",
    "dataset = ReviewDataset.load_dataset_and_make_vectorizer(args.review_csv)\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "# model\n",
    "classifier = ReviewClassifier(num_features=len(vectorizer.review_vocab))\n",
    "classifier = classifier.to(args.device)\n",
    "# loss and optimizer\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bare-bones training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an **inner** loop over minibatches in the dataset, and an **outer** loop, which repeats the inner loop a number of times.\n",
    "In the inner loop, **losses** are computed for each **minibatch**, and the optimizer is used to update the model parameters.\n",
    "\n",
    "----------------\n",
    "\n",
    "Given how we’ve constructed our dataset, the **split** should always be set **before** **generate_batches**() is called\n",
    "\n",
    "-----------------\n",
    "\n",
    "- The .eval() method makes the model parameters **immutable** and **disables** **dropout**.\n",
    "- disables computation of the **loss** and **propagation** of gradients back to the parameters\n",
    "  - This is important because we do not want the model **adjusting** its parameters relative to **validation** data. Instead, we want this data to serve as a measure of how well the model is performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_index in range(args.num_epochs):\n",
    "    train_state['epoch_index'] = epoch_index\n",
    "\n",
    "    # Iterate over training dataset\n",
    "\n",
    "    # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "    dataset.set_split('train') # train for now, then to 'val' later when we want to measure model performance at the end of the epoch\n",
    "    batch_generator = generate_batches(dataset, \n",
    "                                        batch_size=args.batch_size, \n",
    "                                        device=args.device)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    # indicate that the model is in “training mode” and the model parameters are mutable\n",
    "    # also enables regularization mechanisms like dropout\n",
    "    classifier.train() \n",
    "    \n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        # the training routine is these 5 steps:\n",
    "\n",
    "        # --------------------------------------\n",
    "        # step 1. zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # step 2. compute the output\n",
    "        y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
    "\n",
    "        # step 3. compute the loss\n",
    "        loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "        # step 4. use loss to produce gradients\n",
    "        # resulting in gradients being propagated to each parameter.\n",
    "        loss.backward()\n",
    "\n",
    "        # step 5. use optimizer to take gradient step\n",
    "        optimizer.step()\n",
    "        # -----------------------------------------\n",
    "        # compute the accuracy\n",
    "        acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "        # update bar\n",
    "        train_bar.set_postfix(loss=running_loss, \n",
    "                                acc=running_acc, \n",
    "                                epoch=epoch_index)\n",
    "        # The training state is first updated with the final loss and accuracy values.\n",
    "        train_bar.update() \n",
    "\n",
    "    train_state['train_loss'].append(running_loss)\n",
    "    train_state['train_acc'].append(running_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Different between **val** & **test**:\n",
    "- the test set should be run as **little** as possible. \n",
    "- Each time you run a trained model on the test set, make a new model decision (such as changing the size of the layers), and remeasure the new retrained model on the test set, you are **biasing** your modeling decisions toward the **test** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset,\n",
    "                    batch_size=args.batch_size,\n",
    "                    device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
    "    loss_batch = loss.item()\n",
    "    running_loss += (loss_batch - running_loss) / (batch_index + 1)\n",
    "    # compute the accuracy\n",
    "    acc_batch = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "    running_acc += (acc_batch - running_acc) / (batch_index + 1)\n",
    "    train_state['test_loss'] = running_loss\n",
    "    train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference: Printing the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(review, classifier, vectorizer,\n",
    "                    decision_threshold=0.5):\n",
    "    \"\"\"Predict the rating of a review\n",
    "    Args:\n",
    "        review (str): the text of the review\n",
    "        classifier (ReviewClassifier): the trained model\n",
    "        vectorizer (ReviewVectorizer): the corresponding vectorizer\n",
    "        decision_threshold (float): The numerical boundary which\n",
    "                                    separates the rating classes\n",
    "    \"\"\"\n",
    "    review = preprocess_text(review)\n",
    "    vectorized_review = torch.tensor(vectorizer.vectorize(review))\n",
    "    result = classifier(vectorized_review.view(1, -1))\n",
    "    probability_value = F.sigmoid(result).item()\n",
    "    index = 1\n",
    "    if probability_value < decision_threshold:\n",
    "        index = 0\n",
    "    return vectorizer.rating_vocab.lookup_index(index)\n",
    "test_review = \"this is a pretty awesome book\"\n",
    "prediction = predict_rating(test_review, classifier, vectorizer)\n",
    "print(\"{} -> {}\".format(test_review, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort weights\n",
    "fc1_weights = classifier.fc1.weight.detach()[0]\n",
    "_, indices = torch.sort(fc1_weights, dim=0, descending=True)\n",
    "indices = indices.numpy().tolist()\n",
    "\n",
    "# Top 20 words\n",
    "print(\"Influential words in Positive Reviews:\")\n",
    "print(\"--------------------------------------\")\n",
    "for i in range(20):\n",
    "    print(vectorizer.review_vocab.lookup_index(indices[i]))\n",
    "    \n",
    "    \n",
    "\"\"\" Oupput:\n",
    "Influential words in Positive Reviews:\n",
    "--------------------------------------\n",
    "great\n",
    "awesome\n",
    "amazing\n",
    "love\n",
    "friendly\n",
    "delicious\n",
    "best\n",
    "excellent\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "# Top 20 negative words\n",
    "print(\"Influential words in Negative Reviews:\")\n",
    "print(\"--------------------------------------\")\n",
    "indices.reverse()\n",
    "for i in range(20):\n",
    "print(vectorizer.review_vocab.lookup_index(indices[i]))\n",
    "\n",
    "\"\"\" output\n",
    "Influential words in Negative Reviews:\n",
    "--------------------------------------\n",
    "worst\n",
    "horrible\n",
    "mediocre\n",
    "terrible\n",
    "not\n",
    "rude\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General utilities: seed, mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04c2c190d8d0e7e5e1678786cf96c5fe54de7e069d5117ea2521e84529e5d561"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
