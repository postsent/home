
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Image classification &#8212; My AI Notebook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=c1a6f12f" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=949a1ff5" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=ff8fa330"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=97881d71"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ds-courses/unsw/9444/9444-project';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Characters, Spirals and Hidden Unit Dynamics" href="assignment1/assignment1.html" />
    <link rel="prev" title="Deep Learning (UNSW)" href="9444-intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">My AI Notebook</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://postsent.github.io/home/">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reference.html">Acknowledgement</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Research</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../research/polyu/dp/report.html">Data Pruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../research/polyu/dd/report.html">Dataset Distillation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../research/polyu/story/page.html">DD Motivation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Courses</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="9444-intro.html">Deep Learning (UNSW)</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Image classification</a></li>








<li class="toctree-l2"><a class="reference internal" href="assignment1/assignment1.html">Characters, Spirals and Hidden Unit Dynamics</a></li>




















</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../3900/3900-intro.html">Capstone (UNSW)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../3900/project/3900-project.html"><strong>Chatbot</strong></a></li>






</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../3431/3431-intro.html">ROS &amp; CV (UNSW)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../3431/project/project.html">Mini self-driving</a></li>









</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../usyd/5046/5046-intro.html">NLP (USYD)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../usyd/5046/a2/a2.html">Report - In-game Toxicity Detection</a></li>







<li class="toctree-l2"><a class="reference internal" href="../../usyd/5046/a2.html">In Game Toxicity seq2seq classification</a></li>





<li class="toctree-l2"><a class="reference internal" href="../../usyd/5046/a1.html">Binary text classification</a></li>






</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../9417/9417-intro.html">Machine Learning (UNSW)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../9417/9417-basic.html">Basic with examples</a></li>







<li class="toctree-l2"><a class="reference internal" href="../9417/9417-project.html">Project - Classification</a></li>








<li class="toctree-l2"><a class="reference internal" href="../9417/9417-report/report.html">Project - report</a></li>







</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../9517/9517-intro.html">Computer Vision (UNSW)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../9517/9517-a1-code.html">Basic image processing, thresholding, count cells</a></li>



<li class="toctree-l2"><a class="reference internal" href="../9517/9517-a1/report.html">Report on Basic image processing, etc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../9517/9517-lane_detection.html">Lane detection</a></li>





<li class="toctree-l2"><a class="reference internal" href="../9517/9517-vehicle-detection.html">Vehicle detection (by teammate)</a></li>




</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../usyd/5349/5349-intro.html">Cloud Computing (USYD)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../usyd/5349/a2/a2.html">Data Preprocessing and Performance Tuning with Spark</a></li>









<li class="toctree-l2"><a class="reference internal" href="../../usyd/5349/a2.html">Data Preprocessing and Performance Tuning with Spark</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usyd/5349/a1.html">Text Analysis with Spark RDD API</a></li>



<li class="toctree-l2"><a class="reference internal" href="../../usyd/5349/a1-report.html">Report – Text Analysis with Spark RDD API</a></li>






</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../usyd/5338/5338-intro.html">NoSQL &amp; Neo4j (USYD)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../usyd/5338/a1.html">NoSQL basic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usyd/5338/a2.html">NoSQL Aggregation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usyd/5338/a2-report/report.html"><strong>Performance Observation Task</strong></a></li>





<li class="toctree-l2"><a class="reference internal" href="../../usyd/5338/a3.html">Neo4j Basic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usyd/5338/a4.html">Neo4j Query</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../usyd/5048/5048-intro.html">Visual Analytics (USYD)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../usyd/5048/individual.html">Individual Report</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usyd/5048/group.html">Group Report (My part)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../usyd/5328/5328-intro.html">Advance ML (USYD)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../usyd/5328/a1.html">NMF</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usyd/5328/a2.html">Label Noise Learning</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../9418/9418-intro.html">PGM (UNSW)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../9418/9418-EDA.html">EDA on Times Series Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../9418/9418-project.html">Time series project code</a></li>






<li class="toctree-l2"><a class="reference internal" href="../9418/9418-project/report.html">Time series report</a></li>





</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../ml/regression/regression.html">Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../ml/regression/p1-crypto-prediction.html">Crypto Prediction</a></li>



</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ml/classification/classification.html">Classification (placeholder)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ml/time-series/time-series.html">Time Series (placeholder)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ml/ml.html">General</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../dl/dl.html">General</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">NLP</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../nlp/nlp.html">placeholder</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Computer Vision</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../cv/cv.html">Placeholder</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../misc/math.html">Math</a></li>


<li class="toctree-l1"><a class="reference internal" href="../../../misc/misc.html">Misc</a></li>




<li class="toctree-l1"><a class="reference internal" href="../../../misc/term.html">Terminology</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../misc/todo.html">TODO</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Coding Basic</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../python/basic-intro.html">Numpy, Pandas, Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../python/numpy.html">Numpy</a></li>





<li class="toctree-l2"><a class="reference internal" href="../../../python/pandas.html">Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/leetcode.html">Leetcode</a></li>








</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Side Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../side-project/web-scrapter.html">Course Enrolment Scrapter</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unfinished</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../unfinished/pytorch-nlp-bk/nlp-book.html">NLP Book</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../unfinished/pytorch-nlp-bk/intro.html">Intro</a></li>













<li class="toctree-l2"><a class="reference internal" href="../../../unfinished/pytorch-nlp-bk/nn.html">Feed-Forward Networks for NLP</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../../unfinished/pytorch-nlp-bk/prac-ch3.html">Chapter 3</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../unfinished/jigsaw-intro.html">Jigsaw</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../unfinished/jiagsaw-toxic-comment-serverity-rate/README.html">Folder Structure</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../../unfinished/jiagsaw-toxic-comment-serverity-rate/notebooks/simple-rnn.html">Simple</a></li>













<li class="toctree-l2"><a class="reference internal" href="../../../unfinished/jiagsaw-toxic-comment-serverity-rate/notebooks/lstm.html">Upgrade RNN</a></li>



<li class="toctree-l2"><a class="reference internal" href="../../../unfinished/jiagsaw-toxic-comment-serverity-rate/notebooks/helper.html">Common</a></li>

</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../unfinished/nlp-reading.html">Book Reading</a></li>


</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/postsent/home/main?urlpath=tree/docs/ds-courses/unsw/9444/9444-project.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>



<a href="https://github.com/postsent/home" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/ds-courses/unsw/9444/9444-project.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Image classification</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Image classification</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-processing-transformation">Pre-processing/transformation</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection">Model selection</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#wide-resnet">Wide ResNet</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-tuning">Parameter tuning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-rate">Learning rate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#weight-decay">weight decay</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#drop-out">drop out</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-val-split">train_val_split</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#early-stopping">Early stopping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-size">batch size</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#width-factor">width factor</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#depth">depth</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#notes-from-the-paper">Notes from the Paper:</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Implementation</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">Appendix</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="image-classification">
<h1>Image classification<a class="headerlink" href="#image-classification" title="Link to this heading">#</a></h1>
<p><img alt="title" src="../../../_images/9444-project.png" /></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="implementation">
<h1>Implementation<a class="headerlink" href="#implementation" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">student.py</span>

<span class="sd">UNSW COMP9444 Neural Networks and Deep Learning</span>

<span class="sd">You may modify this file however you wish, including creating additional</span>
<span class="sd">variables, functions, classes, etc., so long as your code runs with the</span>
<span class="sd">hw2main.py file unmodified, and you are only using the approved packages.</span>

<span class="sd">You have been given some default values for the variables train_val_split,</span>
<span class="sd">batch_size as well as the transform function.</span>
<span class="sd">You are encouraged to modify these to improve the performance of your model.</span>

<span class="sd">The variable device may be used to refer to the CPU/GPU being used by PyTorch.</span>
<span class="sd">You may change this variable in the config.py file.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">ceil</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">Below is a slightly modified version of the implementation of Wide ResNet:  https://github.com/meliketoy/wide-resnet.pytorch</span>
<span class="sd">BELOW COMMENT on the network architecture is based on the original paper - Wide Residual Network</span>
<span class="sd">the reference e.g. [1] is also refering to the paper&#39;s reference</span>
<span class="sd">&#39;&#39;&#39;</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">   Answer to Question:</span>

<span class="sd">Briefly describe how your program works, and explain any design and training</span>
<span class="sd">decisions you made along the way.</span>

<span class="sd">Task is to classify 14 different Simpsons Characters .</span>
<span class="sd">Firstly, EDA:</span>
<span class="sd">image is in grayscale, and 64*64</span>
<span class="sd">the distribution of classes is ploted via bar plot and is found to be a unbalanced dataset (523~2146).</span>

<span class="sd">Pre-processing/transformation</span>
<span class="sd">	</span>
<span class="sd">	Initial data augmentation includes random perspective, random crop, Random Horizontal Flip and grayscale.</span>
<span class="sd">	It is realised the model would overfit and so more transforms ()</span>
<span class="sd">	 are added, however,  the original model is then not able to learnt, and it is found the model needs to be a lot complex in order to learn this extra transform dataset.</span>
<span class="sd">	Since both models give similar result (mention below), so the simpler model is chosen and so only 3 transforms are added.</span>
<span class="sd">	The importance of certain transformation is determined by a model that is trained with 95% accuracy, if the new transformation decreases the accuracy within 10%, it is then accepted, however, it is found that most transformation is not needed for this dataset.</span>
<span class="sd">	</span>
<span class="sd">Model selection</span>
<span class="sd">	wide resnet 16 ,w = 5 - 95% - 20MB</span>
<span class="sd">	efficientnetv2 - 95% - 42MB</span>
<span class="sd">	resnet50 - 93% - 40 MB</span>
<span class="sd">	vision transformer or the hybrid variant is not considered since the dataset is small and comparison in Cifar-10 shows that it is not much improvement compared to ResNet.</span>
<span class="sd">	</span>
<span class="sd">	wide resnet is chosen.</span>
<span class="sd">	</span>
<span class="sd">	Firstly, wide resnet converge faster and can achieve 99% test accuracy(not submission) </span>
<span class="sd">	Secondly, the paper - and the Cifar-10 benchmark shows great result and it is No.1 in ranking for SVHN dataset and since Cifar-10 dataset is quite similar to this project dataset in term of size of the data and the dimension of each image, this architecture is selected and adapted.</span>
<span class="sd">	Thirdly, dropout works well with this model and as the dataset is relatively small, dropout is considered a great approach to avoid overfitting</span>
<span class="sd">	Besides, the wide resnet model size can be modified easily with the width factor be the dominating  factor (e.g. 6 -&gt; 4 reduce model size by factor of 2)</span>
<span class="sd">	Lastly, this model allow me to explore the effect between depth and width of the network as well as the standard ResNet architecture, the idea of residual blocks are used widely e.g. in Efficientnet and more.</span>
<span class="sd">	</span>
<span class="sd">	Wide ResNet </span>
<span class="sd">		width vs depth</span>
<span class="sd">		very deep residual network has problem of diminishing feature reuse which makes it slow to train</span>
<span class="sd">		This architecture decrease depth and increase the width of residual blocks</span>
<span class="sd">		dropout </span>
<span class="sd">		could regularize the model and prevent overfitting</span>
<span class="sd">		dropout in residual networks was studied previously to have a negative effect when used in the identity part of the block. </span>
<span class="sd">		In the wide ResNet the autoher argue here that dropout should be inserted between convolutional layers.</span>
<span class="sd">		</span>
<span class="sd">Parameter tuning</span>
<span class="sd">	Learning rate </span>
<span class="sd">		It is adjusted during the training based on the convergence in 10 epoch, if the improvement in 10 epoch is significantly less, then the learning rate is decreased by 10 times manually as what the exponential learning rate decay does.</span>
<span class="sd">		It is sometimes increase/decrease 80% to check whether it stuck at local minimum and step size too big</span>
<span class="sd">	weight decay</span>
<span class="sd">		it is initially set as 5e-4 compared with the standard 1.5e-4 to avoid overfitting</span>
<span class="sd">		once closer to 95%, it is adjusted slightly to ensure the model can continue to learn</span>
<span class="sd">	drop out</span>
<span class="sd">		drop out = 0.5 is considered to a bit high and the model stops improving at 91%.</span>
<span class="sd">		drop out = 0.3 still seems to stop the model from improving from 96%</span>
<span class="sd">		drop out = 0.1 </span>
<span class="sd">		The reason could be some less important but still crucial feature with less weight is constantly dropped and cause the model to stop learning</span>
<span class="sd">	train_val_split</span>
<span class="sd">		0.8 - is used initially to testify the model selection </span>
<span class="sd">		0.95 is used once the model converged and stop improving</span>
<span class="sd">	early stopping</span>
<span class="sd">		It is found that it gives up to 2% improvement if the model is stopped early when the testing accuracy does not improve much anymore.</span>
<span class="sd">	width factor</span>
<span class="sd">		width of 6 can give 99.48% in the test set but around 95% in submission and so it is reduced as it is though to overfit since the model is too complex</span>
<span class="sd">		width of 2 is found not learning at the end</span>
<span class="sd">	depth</span>
<span class="sd">		depth of 12 is found to learn really slowly at the end</span>
<span class="sd">	kernel size of first convolution layer and image size</span>
<span class="sd">		the bottleneck of the time complexity is the ratio between the size of the image vs the kernel size of the first convolution layer</span>
<span class="sd">		Since the size needs to match with the input size, so only certain set of kernel + padding+ stride combo can be used based on the formula</span>
<span class="sd">	batch size</span>
<span class="sd">		smaller batch size could have effect of regularising and based on experiment 96 is chosen.</span>
<span class="sd">Notes from the Paper:</span>
<span class="sd">	ncreasing both depth and width helps until the number of parameters becomes too high and stronger regularization is needed</span>
<span class="sd">	widening consistently improves performance across residual networks of different depth;</span>
<span class="sd">Implementation</span>
<span class="sd">	</span>
<span class="sd">	Follow from the original paper &quot;use SGD with Nesterov momentum and cross-entropy loss, initial learning rate is set to 0.1, weight decay to 0.0005, momentum to 0.9&quot;</span>
<span class="sd">	Minibatch size = 96</span>
<span class="sd">	the test set from train_test_split is used as an indicator of improvement and generalisation of the network, however, this does not guarantee the </span>
<span class="sd">Observation</span>
<span class="sd">	Adam could be better than SGD for resnet50, more than 5% faster convergence</span>
<span class="sd">Future Improvement</span>
<span class="sd">	cutMix, learning rate scheduler are some examples of data augmentation that may improve the result </span>
<span class="sd">Result</span>

<span class="sd">appendix</span>
<span class="sd">	</span>
<span class="sd">	links that inferenced</span>
<span class="sd">		</span>
<span class="sd">		wide Resnet paper: 1605.07146v2.pdf (arxiv.org)</span>
<span class="sd">		</span>
<span class="sd">		batch size: How to Control the Stability of Training Neural Networks With the Batch Size (machinelearningmastery.com)</span>
<span class="sd">		</span>
<span class="sd">		transform: Illustration of transforms — Torchvision 0.10.0 documentation (pytorch.org)</span>
<span class="sd">		</span>
<span class="sd">		how to improve efficientnet: Image classification via fine-tuning with EfficientNet (keras.io)</span>
<span class="sd">			</span>
<span class="sd">		Enetv2 implementation link: https://github.com/d-li14/efficientnetv2.pytorch/blob/775326e6c16bfc863e9b8400eca7d723dbfeb06e/effnetv2.py#L16</span>
<span class="sd">		</span>
<span class="sd">		parameter tuning for resNet https://arxiv.org/pdf/2103.07579v1.pdf</span>
<span class="sd">		</span>
<span class="sd">		deep vs width: https://stats.stackexchange.com/questions/222883/why-are-neural-networks-becoming-deeper-but-not-wider</span>
<span class="sd">		</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="n">data_path</span> <span class="o">=</span> <span class="s2">&quot;/data&quot;</span>

<span class="c1">############################################################################</span>
<span class="c1">######     Specify transform(s) to be applied to the input images     ######</span>
<span class="c1">############################################################################</span>
<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">mode</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Called when loading the data. Visit this URL for more information:</span>
<span class="sd">    https://pytorch.org/vision/stable/transforms.html</span>
<span class="sd">    You may specify different transforms for training and testing</span>

<span class="sd">    visulsation of transformation - https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py</span>
<span class="sd">    since the dataset is relatively small, more transforms are used to avoid overfitting</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Grayscale</span><span class="p">(</span><span class="n">num_output_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> 
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomPerspective</span><span class="p">(</span><span class="n">distortion_scale</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span><span class="c1"># Since cropping is done after padding, https://pytorch.org/vision/stable/transforms.html</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">])</span>
        <span class="p">])</span> <span class="c1"># #1 channel so len = 1, keep range to [-1,1] more explanation - https://discuss.pytorch.org/t/understanding-transform-normalize/21730</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Grayscale</span><span class="p">(</span><span class="n">num_output_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> 
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">])</span>
        <span class="p">])</span>

    
<span class="kn">import</span> <span class="nn">torch.nn.init</span> <span class="k">as</span> <span class="nn">init</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">conv3x3</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">out_planes</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span> <span class="c1"># (n +2p -k) / s + 1, here: (32 + 2*1 - 3)/1 + 1 = 32</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">out_planes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">wide_basic</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Page 4</span>
<span class="sd">    two consecutive 3 × 3 convolutions with batch normalization and ReLU</span>
<span class="sd">    preceding convolution: conv3×3-conv3×3</span>
<span class="sd">    Compared to the original architecture, the order of layers is changed from:</span>
<span class="sd">    conv-BN-ReLU to BN-ReLU-conv</span>
<span class="sd">    There is another type of blocks in standard ResNet called BOTTLENECK, however, since it thinner the network,</span>
<span class="sd">    and the purpose of the paper is depth vs width, so it is not considered here.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">wide_basic</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">in_planes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">planes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">shortcut</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">in_planes</span> <span class="o">!=</span> <span class="n">planes</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shortcut</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)))</span>
        <span class="n">out</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shortcut</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># shortcut concept in residual net</span>

        <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span> <span class="nc">WideResNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Top of page 4 shows the overall network architure in a table</span>
<span class="sd">    Small 3×3 filters are shown to be more effective [26, 32]</span>
<span class="sd">    it consists of an initial convolutional layer conv1 that is followed by </span>
<span class="sd">    3 groups (each of size N) of residual blocks conv2, conv3 and conv4, followed by </span>
<span class="sd">    average pooling and final classification layer</span>
<span class="sd">    * Size of conv1 is fixed </span>
<span class="sd">    * introduced widening factor k scales the width of the residual blocks in the three groups conv2-4 </span>
<span class="sd">    * a dropout layer into each residual block between convolutions to avoid heavy augmentation</span>

<span class="sd">    Experiment result:</span>
<span class="sd">    * blocks (consist of convolution layers with different kernel size) with comparable number of parameters turned out to give more or less the same results</span>
<span class="sd">    * B(3,3) - original «basic» block - 2 3*3 convolution layers gives the best result compared to kernel size</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">widen_factor</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        @depth: deepening factor (refers to l in the paper) is the number of convolutions in a block</span>
<span class="sd">        @widen_factor: k multiplies the number of features in convolutional layers</span>
<span class="sd">        baseline «basic» block corresponds to l = 2, k = 1.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">WideResNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">n_classes</span><span class="o">=</span><span class="mi">14</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_planes</span> <span class="o">=</span> <span class="mi">16</span>

        <span class="k">assert</span> <span class="p">((</span><span class="n">depth</span><span class="o">-</span><span class="mi">4</span><span class="p">)</span><span class="o">%</span><span class="mi">6</span> <span class="o">==</span><span class="mi">0</span><span class="p">),</span> <span class="s1">&#39;Wide-resnet depth should be 6n+4&#39;</span>
        <span class="n">n</span> <span class="o">=</span> <span class="p">(</span><span class="n">depth</span><span class="o">-</span><span class="mi">4</span><span class="p">)</span><span class="o">/</span><span class="mi">6</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">widen_factor</span>

        <span class="n">nStages</span> <span class="o">=</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="o">*</span><span class="n">k</span><span class="p">,</span> <span class="mi">32</span><span class="o">*</span><span class="n">k</span><span class="p">,</span> <span class="mi">64</span><span class="o">*</span><span class="n">k</span><span class="p">]</span> <span class="c1"># Original architecture(ResNet) is equivalent to k = 1.</span>
        <span class="n">in_channel</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv3x3</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span><span class="n">nStages</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wide_layer</span><span class="p">(</span><span class="n">wide_basic</span><span class="p">,</span> <span class="n">nStages</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wide_layer</span><span class="p">(</span><span class="n">wide_basic</span><span class="p">,</span> <span class="n">nStages</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">n</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wide_layer</span><span class="p">(</span><span class="n">wide_basic</span><span class="p">,</span> <span class="n">nStages</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">n</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">nStages</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nStages</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">n_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_wide_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
        <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="n">stride</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">stride</span> <span class="ow">in</span> <span class="n">strides</span><span class="p">:</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">block</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">stride</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">in_planes</span> <span class="o">=</span> <span class="n">planes</span>

        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
    
<span class="k">def</span> <span class="nf">get_class_weight</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">os.path</span>

    <span class="c1"># path joining version for other paths</span>
    <span class="kn">import</span> <span class="nn">os</span>

    <span class="n">data_dir</span> <span class="o">=</span> <span class="s2">&quot;./data&quot;</span>
    <span class="n">dir_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">o</span><span class="p">)</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span> <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span><span class="n">o</span><span class="p">))]</span>

    <span class="n">n_files</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dir_list</span><span class="p">:</span>
        <span class="n">nf</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
        <span class="n">n_files</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nf</span><span class="p">)</span>
        
    <span class="n">max_class</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_files</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">max_class</span><span class="o">/</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">n_files</span><span class="p">]</span>
    <span class="n">class_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">class_weights</span>  <span class="c1"># weighted - use the min(n_class) / all n_classes, min_class = 2</span>

<span class="n">_net</span> <span class="o">=</span> <span class="n">WideResNet</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="c1">#_net.load_state_dict(torch.load(&quot;./checkModel10.pth&quot;))</span>
<span class="n">class_weights</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.65</span><span class="p">,</span><span class="mf">4.1</span><span class="p">,</span><span class="mf">1.73</span><span class="p">,</span><span class="mf">1.97</span><span class="p">,</span><span class="mf">2.42</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.94</span><span class="p">,</span><span class="mf">1.71</span><span class="p">,</span><span class="mf">1.8</span><span class="p">,</span><span class="mf">2.19</span><span class="p">,</span><span class="mf">1.59</span><span class="p">,</span><span class="mf">1.59</span><span class="p">,</span><span class="mf">1.96</span><span class="p">,</span><span class="mf">2.77</span><span class="p">]</span> <span class="c1">#get_class_weight()</span>
<span class="n">lossFunc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">class_weights</span><span class="p">)</span> <span class="c1"># loss()</span>

<span class="c1">############################################################################</span>
<span class="c1">#######              Metaparameters and training options              ######</span>
<span class="c1">############################################################################</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="s2">&quot;./data&quot;</span>
<span class="n">train_val_split</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">96</span> <span class="c1"># https://github.com/facebookresearch/LaMCTS/blob/master/LaNAS/LaNet/CIFAR10/train.py</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">200</span> <span class="c1"># since resnet50 140 ep takes 90mb, 50 also 90mb</span>
<span class="n">_optimiser</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="pre-processing-transformation">
<h1>Pre-processing/transformation<a class="headerlink" href="#pre-processing-transformation" title="Link to this heading">#</a></h1>
<p>Initial data augmentation includes resize(32) random perspective, random crop, Random Horizontal Flip, mean/std normalisation and grayscale.
It is realised the model would overfit and so more transforms are added (most transform except for those applies to RGB image). However,  the original model is then failed to be learnt, and more complexity is needed to be added to the model for it to learn this extra transformed dataset.</p>
<p>Since Efficientnet and resnet and wide resnet models all give a similar result (mention below), so the simpler and more flexible model is chosen with only 3 transforms are added.
The importance of certain transformations is determined by a model that is trained with 95% accuracy, if the new transformation decreases the accuracy within 10%, it is then accepted, however, it is found that most transformation is redundant for this dataset.</p>
<p>Moreover, the dataset is found to be unbalanced (500+ ~ 2000+), and a class weighted (ratio is as maximum class data among all classes/each individual class data number) is added to the loss function to solve this issue. For example, a dataset with 1 positive class data and 100 negatives. The update weighted for the 1 will be 100/1 higher. This is a sampling weight technique.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="model-selection">
<h1>Model selection<a class="headerlink" href="#model-selection" title="Link to this heading">#</a></h1>
<p>Note:
since the Cifar-10 dataset is quite similar to this project dataset in term of size of the data and the dimension of each image, the benchmark of it is used as a guide on what model to try.</p>
<p>wide resnet 16 ,w = 6 - 95% - 20MB
wide 16 w = 4 – 94%, 10mb
efficientnetv2 - 95% - 42MB
resnet50 - 93% - 40 MB
vision transformer or the hybrid variant is not considered since the dataset is small and benchmark in Cifar-10 shows that it is not much different compared to ResNet.</p>
<p>Firstly, wide resnet 16 (w = 6) converge faster and can achieve 99% test accuracy(but not submission)</p>
<p>Secondly, the paper - and the Cifar-10 benchmark shows a great result and it is No.1 in ranking for SVHN dataset and high in the Cifar-10 dataset.
Therefore, this architecture is selected and adapted.</p>
<p>Thirdly, dropout works well with this model and since the dataset is relatively small, dropout is considered as a great approach to solve overfitting problem.
Besides, the wide resnet model size can be modified easily with the width factor be the dominating  factor (e.g. 6 -&gt; 4 reduce the model size approximately by a factor of 2)</p>
<p>Lastly, this model allows me to explore the effect between depth and width of the network as well as the standard ResNet architecture, the idea of residual blocks is founded used widely e.g. in Efficientnet and other models.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="wide-resnet">
<h1>Wide ResNet<a class="headerlink" href="#wide-resnet" title="Link to this heading">#</a></h1>
<p>This model is primarily used to compare the effect of width vs depth.
Below is quote from the author of the wide resnet paper:
very deep residual network has a problem of diminishing feature reuse which makes it slow to train. This architecture decreases the depth and increases the width of residual blocks
dropout could regularize the model and prevent overfitting, dropout in residual networks was studied previously to have a negative effect when used in the identity part of the block.
In the wide ResNet, the author argues that dropout should be inserted between convolutional layers instead of within the identity part of the blocks.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="parameter-tuning">
<h1>Parameter tuning<a class="headerlink" href="#parameter-tuning" title="Link to this heading">#</a></h1>
<section id="learning-rate">
<h2>Learning rate<a class="headerlink" href="#learning-rate" title="Link to this heading">#</a></h2>
<p>It is adjusted during the training based on the convergence in each 10 epoch, if the improvement after one 10 epoch is significantly less than the previous, then the learning rate is decreased by 10 times manually as what the typical learning rate decay does.
Increases/decreases 80% is also tried to check whether the model is stucked at a local minimum and step size too big</p>
</section>
<section id="weight-decay">
<h2>weight decay<a class="headerlink" href="#weight-decay" title="Link to this heading">#</a></h2>
<p>it is initially set as 5e-4 compared with the standard 1.5e-4 to avoid overfitting
once closer to 95%, it is adjusted slightly to ensure the model can continue to learn</p>
</section>
<section id="drop-out">
<h2>drop out<a class="headerlink" href="#drop-out" title="Link to this heading">#</a></h2>
<p>drop out = 0.5 is considered to be a bit high and the model stops improving at 91%.
drop out = 0.3 still seems to stop the model from improving from 96%
drop out = 0.1
The reason could be some less important but still crucial feature with less weight is constantly dropped and cause the model to stop learning</p>
</section>
<section id="train-val-split">
<h2>train_val_split<a class="headerlink" href="#train-val-split" title="Link to this heading">#</a></h2>
<p>0.8 - is used initially to testify the model selection
0.95 is used once the model converged and stop improving</p>
</section>
<section id="early-stopping">
<h2>Early stopping<a class="headerlink" href="#early-stopping" title="Link to this heading">#</a></h2>
<p>It is found that it gives up to 2% improvement if the model is stopped early when the testing accuracy does not improve much anymore.
kernel size of first convolution layer and image size
the bottleneck of the time complexity is the ratio between the size of the image vs the kernel size of the first convolution layer
Since the size needs to match with the input size, so only a certain set of kernel + padding+ stride combo can be used based on the formula</p>
</section>
<section id="batch-size">
<h2>batch size<a class="headerlink" href="#batch-size" title="Link to this heading">#</a></h2>
<p>smaller batch size could have the effect of regularising and based on experiment 96 is chosen.</p>
</section>
<section id="width-factor">
<h2>width factor<a class="headerlink" href="#width-factor" title="Link to this heading">#</a></h2>
<p>width of 6 can give 99.48% in the test set but around 95% in submission and so it is reduced as it is thought to overfit since the model is too complex
width of 2 is found not learning at the end</p>
</section>
<section id="depth">
<h2>depth<a class="headerlink" href="#depth" title="Link to this heading">#</a></h2>
<p>depth of 12 is found to learn exceptionally slow at the end</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="notes-from-the-paper">
<h1>Notes from the Paper:<a class="headerlink" href="#notes-from-the-paper" title="Link to this heading">#</a></h1>
<p>increasing both depth and width helps until the number of parameters becomes too high and stronger regularization is needed
widening consistently improves performance across residual networks of different depth;</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>Implementation<a class="headerlink" href="#id1" title="Link to this heading">#</a></h1>
<p>Follow from the original paper “use SGD with Nesterov momentum and cross-entropy loss, the initial learning rate is set to 0.1, weight decay to 0.0005, momentum to 0.9”
Minibatch size = 96
the test set from train_test_split is used as an indicator of improvement and generalisation of the network, however, this does not guarantee the
Observation
Adam could be better than SGD for resnet50, with more than 5% faster convergence
Future Improvement
cutMix, learning rate scheduler are some examples of data augmentation that may improve the result, ZCA whitening as mentioned in the paper.
Result</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="appendix">
<h1>Appendix<a class="headerlink" href="#appendix" title="Link to this heading">#</a></h1>
<p>links used as an inference</p>
<p>wide Resnet paper: 1605.07146v2.pdf (<a class="reference external" href="http://arxiv.org">arxiv.org</a>)</p>
<p>batch size: How to Control the Stability of Training Neural Networks With the Batch Size (<a class="reference external" href="http://machinelearningmastery.com">machinelearningmastery.com</a>)</p>
<p>transform: Illustration of transforms — Torchvision 0.10.0 documentation (<a class="reference external" href="http://pytorch.org">pytorch.org</a>)</p>
<p>how to improve efficientnet: Image classification via fine-tuning with EfficientNet (<a class="reference external" href="http://keras.io">keras.io</a>)</p>
<p>Enetv2 implementation link: <a class="github reference external" href="https://github.com/d-li14/efficientnetv2.pytorch/blob/775326e6c16bfc863e9b8400eca7d723dbfeb06e/effnetv2.py#L16">d-li14/efficientnetv2.pytorch</a></p>
<p>parameter tuning for resNet <a class="reference external" href="https://arxiv.org/pdf/2103.07579v1.pdf">https://arxiv.org/pdf/2103.07579v1.pdf</a></p>
<p>deep vs width: <a class="reference external" href="https://stats.stackexchange.com/questions/222883/why-are-neural-networks-becoming-deeper-but-not-wider">https://stats.stackexchange.com/questions/222883/why-are-neural-networks-becoming-deeper-but-not-wider</a></p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./ds-courses\unsw\9444"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="9444-intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Deep Learning (UNSW)</p>
      </div>
    </a>
    <a class="right-next"
       href="assignment1/assignment1.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Characters, Spirals and Hidden Unit Dynamics</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Image classification</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-processing-transformation">Pre-processing/transformation</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection">Model selection</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#wide-resnet">Wide ResNet</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-tuning">Parameter tuning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-rate">Learning rate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#weight-decay">weight decay</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#drop-out">drop out</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-val-split">train_val_split</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#early-stopping">Early stopping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-size">batch size</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#width-factor">width factor</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#depth">depth</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#notes-from-the-paper">Notes from the Paper:</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Implementation</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">Appendix</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Jerry
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2021.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>