
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Intro &#8212; My Jupter Notebook on data science.</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Feed-Forward Networks for NLP" href="nn.html" />
    <link rel="prev" title="NLP Book" href="nlp-book.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">My Jupter Notebook on data science.</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://postsent.github.io/">
   Back to Blog
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../reference.html">
   References
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml/regression/regression.html">
   Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml/regression/p1-crypto-prediction.html">
     Crypto Prediction
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml/classification/classification.html">
   Classification (placeholder)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml/time-series/time-series.html">
   Time Series (placeholder)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml/ml.html">
   General
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Deep Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../dl/dl.html">
   General
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  NLP
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/nlp.html">
   placeholder
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Computer Vision
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../cv/cv.html">
   Placeholder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cv/3431_project/project.html">
   ROS: Cute mini self-driving (UNSW)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data Science Courses
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ds-courses/unsw/9417/9417-intro.html">
   Machine Learning (UNSW)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ds-courses/unsw/9417/9417-basic.html">
     Basic with examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ds-courses/unsw/9417/9417-project.html">
     Project - Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ds-courses/unsw/9418/9418-intro.html">
   PGM (UNSW)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ds-courses/unsw/9418/9418-EDA.html">
     EDA on Times Series Dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ds-courses/unsw/9418/9418-project.html">
     Time series project code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ds-courses/unsw/9418/9418-project/report.html">
     Time series report
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ds-courses/unsw/9517/9517-intro.html">
   Computer Vision (UNSW)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ds-courses/unsw/9517/9517-a1-code.html">
     Basic image processing, thresholding, count cells
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ds-courses/unsw/9517/9517-a1/report.html">
     Report on Basic image processing, etc
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ds-courses/unsw/9517/9517-lane_detection.html">
     Lane detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ds-courses/unsw/9517/9517-vehicle-detection.html">
     Vehicle detection
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ds-courses/unsw/9444/9444-intro.html">
   Deep Learning (UNSW)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ds-courses/unsw/9444/9444-project.html">
     Image classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ds-courses/unsw/9444/assignment1/assignment1.html">
     Characters, Spirals and Hidden Unit Dynamics (Assignment 1)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ds-courses/unsw/3900/3900-intro.html">
   Capstone (UNSW)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ds-courses/unsw/3900/project/3900-project.html">
     <strong>
      COMP3900 – Computer Science Project: Chatbot
     </strong>
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Misc
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../misc/math.html">
   Math
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../misc/misc.html">
   Misc
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../misc/term.html">
   Terminology
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../misc/todo.html">
   TODO
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Coding Basic
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../python/basic-intro.html">
   Numpy, Pandas, Python
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python/numpy.html">
     Numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python/pandas.html">
     Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python/leetcode.html">
     Leetcode
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Unfinished
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="nlp-book.html">
   NLP Book
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="nn.html">
     Feed-Forward Networks for NLP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prac-ch3.html">
     Chapter 3
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../jigsaw-intro.html">
   Jigsaw
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../jiagsaw-toxic-comment-serverity-rate/README.html">
     Folder Structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../jiagsaw-toxic-comment-serverity-rate/notebooks/simple-rnn.html">
     Simple
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../jiagsaw-toxic-comment-serverity-rate/notebooks/lstm.html">
     Upgrade RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../jiagsaw-toxic-comment-serverity-rate/notebooks/helper.html">
     Common
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp-reading.html">
   Book Reading
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/unfinished/pytorch-nlp-bk/intro.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/postsent/nb"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/postsent/nb/main?urlpath=tree/docs/unfinished/pytorch-nlp-bk/intro.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Intro
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#set-seed">
   Set seed
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#one-bot-binary-encoding">
   One bot / Binary encoding
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tf-idf-representation">
   TF-IDF representation
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pytorch-basic">
   Pytorch Basic
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#describe">
     Describe()
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-normal-dist">
     Random normal dist
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-from-list">
     Tensor from list
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensfor-from-numpy">
     Tensfor from numpy
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-properties">
     Tensor properties
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-operations">
     Tensor Operations
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#slicing-and-indexing-a-tensor">
     Slicing and indexing a tensor
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complex-indexing-noncontiguous-indexing-of-a-tensor">
     Complex indexing: noncontiguous indexing of a tensor
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#index-select">
       index_select
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#particular-row-col">
       particular row + col
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#linear-algebra-add-multiplication">
       Linear algebra: add, multiplication
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mm-type-must-be-the-same">
       mm, type must be the same
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensors-and-computational-graphs">
     Tensors and Computational Graphs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#creating-tensors-for-gradient-bookkeeping">
       Creating tensors for gradient bookkeeping
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#requires-grad">
       requires_grad
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#grad">
       .grad
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cuda-tensors">
     CUDA Tensors
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mixing-cuda-tensors-with-cpu-bound-tensors">
       Mixing CUDA tensors with CPU-bound tensors
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#convert-to-same-device">
       convert to same device
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#more-torch-api">
     More torch API
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#un-squeeze">
       (UN)SQUEEZE
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rand">
       RAND
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#normal">
       .normal_()
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#expand">
       expand()
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-engineering">
   Feature engineering
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nltk">
     NLTK
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#n-grams">
     N-grams
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lemmatization">
     lemmatization
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#process-tweets-example">
     Process tweets example
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#categorizing-words-pos-tagging">
     Categorizing Words: POS Tagging
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#activiation-function">
   Activiation Function
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sigmoid">
     Sigmoid
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vanishing-exploding-gradient">
     vanishing/exploding gradient
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tanh">
     Tanh
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#relu">
     Relu
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#softmax">
     Softmax
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loss-functions">
   Loss Functions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-squared-error-loss">
     Mean Squared Error Loss
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#categorical-cross-entropy-loss">
     Categorical Cross-Entropy Loss
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-use-e-in-the-formula">
     why use e in the formula?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#binary-cross-entropy-loss">
     Binary cross-entropy loss
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#supervised-training">
   Supervised Training
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimiser">
     Optimiser
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#instantiating-the-adam-optimizer">
     Instantiating the Adam optimizer
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gradient-descent-overview">
       Gradient Descent overview
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#toy-example">
   Toy Example
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perceptron">
     Perceptron
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vocab-vectoriser-dataloader">
   Vocab, vectoriser, dataloader
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-yelp-review-dataset">
   The Yelp Review Dataset
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#note">
     Note
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-training-validation-and-testing-splits">
     Creating training, validation, and testing splits
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#minimally-cleaning-the-data">
     Minimally cleaning the data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-vocabulary">
     The Vocabulary
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#class-code">
       Class code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vectorizer-one-hot">
     Vectorizer - One hot
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Class code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-pytorch-dataset-class">
     A PyTorch Dataset class
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Class code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perceptron-classifier">
     Perceptron Classifier
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       Class code
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-route">
   Training Route
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#args-hyperparam-program-options">
     args - hyperparam &amp; program options
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#helper-initial-update-train-state">
     Helper: Initial/update train state,
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bare-bones-training-loop">
     bare-bones training loop
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#code">
       code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#test-set">
     Test set
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inference-printing-the-prediction">
     Inference: Printing the prediction
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inspecting-model-weights">
     Inspecting model weights
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-utilities-seed-mkdir">
     General utilities: seed, mkdir
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more">
   More
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Intro</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Intro
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#set-seed">
   Set seed
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#one-bot-binary-encoding">
   One bot / Binary encoding
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tf-idf-representation">
   TF-IDF representation
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pytorch-basic">
   Pytorch Basic
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#describe">
     Describe()
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-normal-dist">
     Random normal dist
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-from-list">
     Tensor from list
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensfor-from-numpy">
     Tensfor from numpy
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-properties">
     Tensor properties
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-operations">
     Tensor Operations
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#slicing-and-indexing-a-tensor">
     Slicing and indexing a tensor
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complex-indexing-noncontiguous-indexing-of-a-tensor">
     Complex indexing: noncontiguous indexing of a tensor
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#index-select">
       index_select
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#particular-row-col">
       particular row + col
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#linear-algebra-add-multiplication">
       Linear algebra: add, multiplication
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mm-type-must-be-the-same">
       mm, type must be the same
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensors-and-computational-graphs">
     Tensors and Computational Graphs
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#creating-tensors-for-gradient-bookkeeping">
       Creating tensors for gradient bookkeeping
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#requires-grad">
       requires_grad
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#grad">
       .grad
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cuda-tensors">
     CUDA Tensors
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mixing-cuda-tensors-with-cpu-bound-tensors">
       Mixing CUDA tensors with CPU-bound tensors
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#convert-to-same-device">
       convert to same device
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#more-torch-api">
     More torch API
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#un-squeeze">
       (UN)SQUEEZE
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rand">
       RAND
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#normal">
       .normal_()
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#expand">
       expand()
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-engineering">
   Feature engineering
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nltk">
     NLTK
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#n-grams">
     N-grams
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lemmatization">
     lemmatization
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#process-tweets-example">
     Process tweets example
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#categorizing-words-pos-tagging">
     Categorizing Words: POS Tagging
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#activiation-function">
   Activiation Function
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sigmoid">
     Sigmoid
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vanishing-exploding-gradient">
     vanishing/exploding gradient
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tanh">
     Tanh
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#relu">
     Relu
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#softmax">
     Softmax
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loss-functions">
   Loss Functions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-squared-error-loss">
     Mean Squared Error Loss
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#categorical-cross-entropy-loss">
     Categorical Cross-Entropy Loss
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-use-e-in-the-formula">
     why use e in the formula?
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#binary-cross-entropy-loss">
     Binary cross-entropy loss
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#supervised-training">
   Supervised Training
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview">
     Overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimiser">
     Optimiser
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#instantiating-the-adam-optimizer">
     Instantiating the Adam optimizer
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gradient-descent-overview">
       Gradient Descent overview
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#toy-example">
   Toy Example
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perceptron">
     Perceptron
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vocab-vectoriser-dataloader">
   Vocab, vectoriser, dataloader
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-yelp-review-dataset">
   The Yelp Review Dataset
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#note">
     Note
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-training-validation-and-testing-splits">
     Creating training, validation, and testing splits
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#minimally-cleaning-the-data">
     Minimally cleaning the data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-vocabulary">
     The Vocabulary
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#class-code">
       Class code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vectorizer-one-hot">
     Vectorizer - One hot
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Class code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-pytorch-dataset-class">
     A PyTorch Dataset class
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Class code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#perceptron-classifier">
     Perceptron Classifier
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       Class code
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-route">
   Training Route
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#args-hyperparam-program-options">
     args - hyperparam &amp; program options
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#helper-initial-update-train-state">
     Helper: Initial/update train state,
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bare-bones-training-loop">
     bare-bones training loop
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#code">
       code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#test-set">
     Test set
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inference-printing-the-prediction">
     Inference: Printing the prediction
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inspecting-model-weights">
     Inspecting model weights
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-utilities-seed-mkdir">
     General utilities: seed, mkdir
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more">
   More
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="intro">
<h1>Intro<a class="headerlink" href="#intro" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline 
<span class="kn">from</span> <span class="nn">IPython.core.interactiveshell</span> <span class="kn">import</span> <span class="n">InteractiveShell</span>
<span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">ast_node_interactivity</span> <span class="o">=</span> <span class="s1">&#39;all&#39;</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="set-seed">
<h1>Set seed<a class="headerlink" href="#set-seed" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">seed</span> <span class="o">=</span> <span class="mi">23</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;torch._C.Generator at 0x2614acf7db0&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="one-bot-binary-encoding">
<h1>One bot / Binary encoding<a class="headerlink" href="#one-bot-binary-encoding" title="Permalink to this headline">¶</a></h1>
<p>Example 1-1. Generating a “collapsed” one-hot or binary representation using scikit-learn</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
 
<span class="n">sentence1</span> <span class="o">=</span> <span class="s1">&#39;Time flies flies like an arrow.&#39;</span>
<span class="n">sentence2</span> <span class="o">=</span> <span class="s1">&#39;Fruit flies like a banana.&#39;</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence1</span><span class="p">,</span> <span class="n">sentence2</span><span class="p">]</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;an&#39;</span><span class="p">,</span> <span class="s1">&#39;arrow&#39;</span><span class="p">,</span> <span class="s1">&#39;banana&#39;</span><span class="p">,</span> <span class="s1">&#39;flies&#39;</span><span class="p">,</span> <span class="s1">&#39;fruit&#39;</span><span class="p">,</span> <span class="s1">&#39;like&#39;</span><span class="p">,</span> <span class="s1">&#39;time&#39;</span><span class="p">]</span>
<span class="c1">#note here a, an are treated as one word, so only an is shwon</span>
<span class="n">one_hot_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">one_hot</span> <span class="o">=</span> <span class="n">one_hot_vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">one_hot</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">one_hot</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">vocab</span><span class="p">,</span> <span class="c1"># cbar is for the heat value illustartion</span>
            <span class="n">yticklabels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Sentence 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Sentence 2&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1, 1, 0, 1, 0, 1, 1],
       [0, 0, 1, 1, 1, 1, 0]], dtype=int64)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:&gt;
</pre></div>
</div>
<img alt="../../_images/intro_6_2.png" src="../../_images/intro_6_2.png" />
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="tf-idf-representation">
<h1>TF-IDF representation<a class="headerlink" href="#tf-idf-representation" title="Permalink to this headline">¶</a></h1>
<p>Example 1-2. Generating a TF-IDF representation using scikit-learn</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
 
<span class="n">tfidf_vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">()</span>
<span class="n">tfidf</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">tfidf</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">vocab</span><span class="p">,</span>
            <span class="n">yticklabels</span><span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Sentence 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Sentence 2&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:&gt;
</pre></div>
</div>
<img alt="../../_images/intro_8_1.png" src="../../_images/intro_8_1.png" />
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="pytorch-basic">
<h1>Pytorch Basic<a class="headerlink" href="#pytorch-basic" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!conda install pytorch torchvision -c pytorch</span>

<span class="k">def</span> <span class="nf">p</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-------&#39;</span><span class="o">+</span><span class="n">t</span><span class="o">+</span><span class="s1">&#39;-------&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="describe">
<h2>Describe()<a class="headerlink" href="#describe" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">describe</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;summarise properties of a tensor x</span>

<span class="sd">    Args:</span>
<span class="sd">        x (tensor): </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Type: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">()))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape/size: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Values: </span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">describe</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type: torch.FloatTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[0., 0., 0.],
        [0., 0., 0.]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="random-normal-dist">
<h2>Random normal dist<a class="headerlink" href="#random-normal-dist" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">describe</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>   <span class="c1"># uniform random</span>
<span class="n">describe</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>  <span class="c1"># random normal</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type: torch.FloatTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[0.5866, 0.0962, 0.1946],
        [0.3136, 0.0838, 0.3909]])
Type: torch.FloatTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[ 0.2589,  0.4765, -0.0993],
        [-0.8002, -0.0610, -0.3848]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="tensor-from-list">
<h2>Tensor from list<a class="headerlink" href="#tensor-from-list" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>  
                 <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type: torch.FloatTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[1., 2., 3.],
        [4., 5., 6.]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="tensfor-from-numpy">
<h2>Tensfor from numpy<a class="headerlink" href="#tensfor-from-numpy" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">npy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">describe</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">npy</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type: torch.DoubleTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[0.9093, 0.7515, 0.5657],
        [0.5321, 0.7644, 0.4786]], dtype=torch.float64)
</pre></div>
</div>
</div>
</div>
</section>
<section id="tensor-properties">
<h2>Tensor properties<a class="headerlink" href="#tensor-properties" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>  
                    <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> 
                 <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> 
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type: torch.FloatTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[1., 2., 3.],
        [4., 5., 6.]])

Type: torch.LongTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[1, 2, 3],
        [4, 5, 6]])

Type: torch.LongTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[1, 2, 3],
        [4, 5, 6]])

Type: torch.FloatTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[1., 2., 3.],
        [4., 5., 6.]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="tensor-operations">
<h2>Tensor Operations<a class="headerlink" href="#tensor-operations" title="Permalink to this headline">¶</a></h2>
<p>randn, add, arange, view/reshape</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span><span class="p">(</span><span class="s1">&#39;randn&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">x</span>

<span class="n">p</span><span class="p">(</span><span class="s1">&#39;add&#39;</span><span class="p">)</span>
<span class="n">describe</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span>

<span class="n">p</span><span class="p">(</span><span class="s1">&#39;arange&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">x</span>

<span class="n">p</span><span class="p">(</span><span class="s1">&#39;view/reshape&#39;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">p</span><span class="p">(</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
<span class="n">describe</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="n">p</span><span class="p">(</span><span class="s1">&#39;transpose&#39;</span><span class="p">)</span>

<span class="n">describe</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-------randn-------
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-0.5208, -0.1943,  0.2444],
        [-0.1555, -0.2432, -0.8521]])
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-------add-------

Type: torch.FloatTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[-1.0416, -0.3887,  0.4888],
        [-0.3111, -0.4865, -1.7041]])

Type: torch.FloatTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[-1.0416, -0.3887,  0.4888],
        [-0.3111, -0.4865, -1.7041]])

-------arange-------
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([0, 1, 2, 3, 4, 5])
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-------view/reshape-------

Type: torch.LongTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[0, 1, 2],
        [3, 4, 5]])

-------sum-------

Type: torch.LongTensor
Shape/size: torch.Size([3])
Values: 
tensor([3, 5, 7])

-------transpose-------

Type: torch.LongTensor
Shape/size: torch.Size([3, 2])
Values: 
tensor([[0, 3],
        [1, 4],
        [2, 5]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="slicing-and-indexing-a-tensor">
<h2>Slicing and indexing a tensor<a class="headerlink" href="#slicing-and-indexing-a-tensor" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">])</span> <span class="c1"># row 0, first two cols</span>

<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type: torch.LongTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[0, 1, 2],
        [3, 4, 5]])

Type: torch.LongTensor
Shape/size: torch.Size([1, 2])
Values: 
tensor([[0, 1]])

Type: torch.LongTensor
Shape/size: torch.Size([])
Values: 
1
</pre></div>
</div>
</div>
</div>
</section>
<section id="complex-indexing-noncontiguous-indexing-of-a-tensor">
<h2>Complex indexing: noncontiguous indexing of a tensor<a class="headerlink" href="#complex-indexing-noncontiguous-indexing-of-a-tensor" title="Permalink to this headline">¶</a></h2>
<section id="index-select">
<h3>index_select<a class="headerlink" href="#index-select" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># indices = torch.LongTensor([0, 2]) </span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">describe</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">indices</span><span class="p">))</span> <span class="c1"># 0, 2th col only</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type: torch.LongTensor
Shape/size: torch.Size([2, 2])
Values: 
tensor([[0, 2],
        [3, 5]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="particular-row-col">
<h3>particular row + col<a class="headerlink" href="#particular-row-col" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span>
<span class="n">p</span><span class="p">()</span>
<span class="n">row_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
<span class="n">row_indices</span>
<span class="n">p</span><span class="p">()</span>
<span class="n">col_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">col_indices</span>
<span class="n">p</span><span class="p">(</span><span class="s1">&#39;particular row col elements&#39;</span><span class="p">)</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">row_indices</span><span class="p">,</span> <span class="n">col_indices</span><span class="p">])</span> <span class="c1"># row0,col0 +  row1,col1</span>
<span class="n">p</span><span class="p">(</span><span class="s1">&#39;cat based rows&#39;</span><span class="p">)</span>
<span class="n">describe</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">p</span><span class="p">(</span><span class="s1">&#39;stack&#39;</span><span class="p">)</span> <span class="c1"># stack another depth, depth: 2, row: 2, col: 2</span>
<span class="n">describe</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0, 1, 2],
        [3, 4, 5]])
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--------------
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([0, 1])
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--------------
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([0, 1])
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-------particular row col elements-------

Type: torch.LongTensor
Shape/size: torch.Size([2])
Values: 
tensor([0, 4])

-------cat based rows-------

Type: torch.LongTensor
Shape/size: torch.Size([4, 3])
Values: 
tensor([[0, 1, 2],
        [3, 4, 5],
        [0, 1, 2],
        [3, 4, 5]])

-------stack-------

Type: torch.LongTensor
Shape/size: torch.Size([2, 2, 3])
Values: 
tensor([[[0, 1, 2],
         [3, 4, 5]],

        [[0, 1, 2],
         [3, 4, 5]]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="linear-algebra-add-multiplication">
<h3>Linear algebra: add, multiplication<a class="headerlink" href="#linear-algebra-add-multiplication" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">x2</span>
<span class="n">x2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># all row, col 1</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[1., 1.],
        [1., 1.],
        [1., 1.]])
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type: torch.FloatTensor
Shape/size: torch.Size([3, 2])
Values: 
tensor([[1., 2.],
        [1., 2.],
        [1., 2.]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="mm-type-must-be-the-same">
<h3>mm, type must be the same<a class="headerlink" href="#mm-type-must-be-the-same" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>

<span class="n">describe</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type: torch.FloatTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[0., 1., 2.],
        [3., 4., 5.]])

Type: torch.FloatTensor
Shape/size: torch.Size([3, 2])
Values: 
tensor([[1., 2.],
        [1., 2.],
        [1., 2.]])

Type: torch.FloatTensor
Shape/size: torch.Size([2, 2])
Values: 
tensor([[ 3.,  6.],
        [12., 24.]])
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="tensors-and-computational-graphs">
<h2>Tensors and Computational Graphs<a class="headerlink" href="#tensors-and-computational-graphs" title="Permalink to this headline">¶</a></h2>
<section id="creating-tensors-for-gradient-bookkeeping">
<h3>Creating tensors for gradient bookkeeping<a class="headerlink" href="#creating-tensors-for-gradient-bookkeeping" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type: torch.FloatTensor
Shape/size: torch.Size([2, 2])
Values: 
tensor([[1., 1.],
        [1., 1.]], requires_grad=True)

True
</pre></div>
</div>
</div>
</div>
</section>
<section id="requires-grad">
<h3>requires_grad<a class="headerlink" href="#requires-grad" title="Permalink to this headline">¶</a></h3>
<p>“When you create a tensor with requires_grad=True, you are requiring PyTorch to manage <strong>bookkeeping</strong> information that computes gradients.
First, PyTorch will keep track of the values of the <strong>forward pass</strong>. Then, at the end of the computations, a single <strong>scalar</strong> is used to compute a backward pass. The <strong>backward pass</strong> is initiated by using the backward() method on a tensor resulting from the evaluation of a loss function. The backward pass computes a gradient value for a tensor object that participated in the forward pass.”</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">5</span><span class="p">)</span> <span class="o">+</span> <span class="mi">3</span>
<span class="n">describe</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>

<span class="n">p</span><span class="p">()</span>

<span class="n">z</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">describe</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="n">z</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type: torch.FloatTensor
Shape/size: torch.Size([2, 2])
Values: 
tensor([[21., 21.],
        [21., 21.]], grad_fn=&lt;AddBackward0&gt;)

False
--------------

Type: torch.FloatTensor
Shape/size: torch.Size([])
Values: 
21.0

False
</pre></div>
</div>
</div>
</div>
</section>
<section id="grad">
<h3>.grad<a class="headerlink" href="#grad" title="Permalink to this headline">¶</a></h3>
<p>the gradient is a value that represents the <strong>slope</strong> of a function output with respect to the <strong>function input</strong>
<strong>Optimizers</strong> use the .grad variable to <strong>update</strong> the values of the <strong>parameters</strong>.</p>
</section>
</section>
<section id="cuda-tensors">
<h2>CUDA Tensors<a class="headerlink" href="#cuda-tensors" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>To use a GPU, you need to first allocate the tensor on the GPU’s memory</p></li>
<li><p>Before it is run on CPU.</p></li>
<li><p>The CUDA API was created by <strong>NVIDIA</strong> and is limited to use on only <strong>NVIDIA GPUs</strong></p></li>
</ul>
<p>Transfering the tensor from the CPU to the GPU while maintaining its underlying type. The preferred method in PyTorch is to be device agnostic and write code that works whether it’s on the GPU or the CPU.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span>

<span class="c1"># preferred method: device agnostic tensor instantiation</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
cuda
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([0.], device=&#39;cuda:0&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">describe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type: torch.cuda.FloatTensor
Shape/size: torch.Size([3, 3])
Values: 
tensor([[0.9864, 0.5348, 0.2743],
        [0.2985, 0.3224, 0.7795],
        [0.5672, 0.4135, 0.9058]], device=&#39;cuda:0&#39;)
</pre></div>
</div>
</div>
</div>
<section id="mixing-cuda-tensors-with-cpu-bound-tensors">
<h3>Mixing CUDA tensors with CPU-bound tensors<a class="headerlink" href="#mixing-cuda-tensors-with-cpu-bound-tensors" title="Permalink to this headline">¶</a></h3>
<p>it is <strong>expensive</strong> to move data back and forth from the GPU. Therefore, the typical procedure involves doing many of the <strong>parallelizable</strong> computations on the GPU and then transferring just the <strong>final result</strong> back to the CPU.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="n">Input</span> <span class="n">In</span> <span class="p">[</span><span class="mi">13</span><span class="p">],</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>

<span class="ne">RuntimeError</span>: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
</pre></div>
</div>
</div>
</div>
</section>
<section id="convert-to-same-device">
<h3>convert to same device<a class="headerlink" href="#convert-to-same-device" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cpu_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cpu_device</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cpu_device</span><span class="p">)</span>
<span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[1.1606, 1.0611, 0.8188],
        [0.4594, 0.7113, 0.9905],
        [0.8951, 0.5917, 1.8479]])
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="more-torch-api">
<h2>More torch API<a class="headerlink" href="#more-torch-api" title="Permalink to this headline">¶</a></h2>
<section id="un-squeeze">
<h3>(UN)SQUEEZE<a class="headerlink" href="#un-squeeze" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>UNSQUEEZE: Returns a new tensor with a dimension of size one <strong>inserted</strong> at the specified position.</p></li>
<li><p>Returns a tensor with all the dimensions of input of size 1 <strong>removed</strong>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([3, 4, 5, 6])
</pre></div>
</div>
</div>
</div>
</section>
<section id="rand">
<h3>RAND<a class="headerlink" href="#rand" title="Permalink to this headline">¶</a></h3>
<p>Returns a tensor filled with random numbers from a uniform distribution on the interval <strong>[0, 1)</strong></p>
</section>
<section id="normal">
<h3>.normal_()<a class="headerlink" href="#normal" title="Permalink to this headline">¶</a></h3>
<p>convert to normal distribution</p>
</section>
<section id="expand">
<h3>expand()<a class="headerlink" href="#expand" title="Permalink to this headline">¶</a></h3>
<p>making copies of existance ones and expand horizontally</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="feature-engineering">
<h1>Feature engineering<a class="headerlink" href="#feature-engineering" title="Permalink to this headline">¶</a></h1>
<section id="nltk">
<h2>NLTK<a class="headerlink" href="#nltk" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">TweetTokenizer</span>

<span class="n">tweet</span> <span class="o">=</span> <span class="sa">u</span><span class="s2">&quot;Snow White and the Seven Degrees </span><span class="se">\</span>
<span class="s2">    #MakeAMovieCold@midnight:-)&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">TweetTokenizer</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">tweet</span><span class="o">.</span><span class="n">lower</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;snow&#39;, &#39;white&#39;, &#39;and&#39;, &#39;the&#39;, &#39;seven&#39;, &#39;degrees&#39;, &#39;#makeamoviecold&#39;, &#39;@midnight&#39;, &#39;:-)&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="n-grams">
<h2>N-grams<a class="headerlink" href="#n-grams" title="Permalink to this headline">¶</a></h2>
<p>sliding window</p>
<p>N-grams are fixed-length (n) consecutive token sequences occurring in the text.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">n_grams</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    takes tokens or text, returns a list of n-grams</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="o">-</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>

<span class="n">cleaned</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mary&#39;</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="s2">&quot;n&#39;t&quot;</span><span class="p">,</span> <span class="s1">&#39;slap&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;witch&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">n_grams</span><span class="p">(</span><span class="n">cleaned</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[&#39;mary&#39;, &#39;,&#39;, &quot;n&#39;t&quot;], [&#39;,&#39;, &quot;n&#39;t&quot;, &#39;slap&#39;], [&quot;n&#39;t&quot;, &#39;slap&#39;, &#39;green&#39;], [&#39;slap&#39;, &#39;green&#39;, &#39;witch&#39;], [&#39;green&#39;, &#39;witch&#39;, &#39;.&#39;]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="lemmatization">
<h2>lemmatization<a class="headerlink" href="#lemmatization" title="Permalink to this headline">¶</a></h2>
<p>Lemmas are root forms of words. Go -&gt; went, goes, etc.</p>
</section>
<section id="process-tweets-example">
<h2>Process tweets example<a class="headerlink" href="#process-tweets-example" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">string</span>

<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">TweetTokenizer</span>

<span class="kn">from</span> <span class="nn">matplotlib.patches</span> <span class="kn">import</span> <span class="n">Ellipse</span>
<span class="kn">import</span> <span class="nn">matplotlib.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> <span class="c1"># Library for linear algebra and math utils</span>


<span class="k">def</span> <span class="nf">process_tweet</span><span class="p">(</span><span class="n">tweet</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Input:</span>
<span class="sd">        tweet: a string containing a tweet</span>
<span class="sd">    Output:</span>
<span class="sd">        tweets_clean: a list of words containing the processed tweet</span>

<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">stemmer</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>
    <span class="n">stopwords_english</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>
    <span class="c1"># remove stock market tickers like $GE</span>
    <span class="n">tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\$\w*&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">tweet</span><span class="p">)</span>
    <span class="c1"># remove old style retweet text &quot;RT&quot;</span>
    <span class="n">tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;^RT[\s]+&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">tweet</span><span class="p">)</span>
    <span class="c1"># remove hyperlinks</span>
    <span class="c1">#tweet = re.sub(r&#39;https?:\/\/.*[\r\n]*&#39;, &#39;&#39;, tweet)</span>
    <span class="n">tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;https?://[^\s\n\r]+&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">tweet</span><span class="p">)</span>
    <span class="c1"># remove hashtags</span>
    <span class="c1"># only removing the hash # sign from the word</span>
    <span class="n">tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;#&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">tweet</span><span class="p">)</span>
    <span class="c1"># tokenize tweets</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">preserve_case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">strip_handles</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                <span class="n">reduce_len</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">tweet_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>

    <span class="n">tweets_clean</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet_tokens</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords_english</span> <span class="ow">and</span>  <span class="c1"># remove stopwords</span>
            <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">):</span>  <span class="c1"># remove punctuation</span>
            <span class="c1"># tweets_clean.append(word)</span>
            <span class="n">stem_word</span> <span class="o">=</span> <span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>  <span class="c1"># stemming word</span>
            <span class="n">tweets_clean</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stem_word</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tweets_clean</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="categorizing-words-pos-tagging">
<h2>Categorizing Words: POS Tagging<a class="headerlink" href="#categorizing-words-pos-tagging" title="Permalink to this headline">¶</a></h2>
<p>part-of-speech (POS) tagging</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="activiation-function">
<h1>Activiation Function<a class="headerlink" href="#activiation-function" title="Permalink to this headline">¶</a></h1>
<section id="sigmoid">
<h2>Sigmoid<a class="headerlink" href="#sigmoid" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[ f(x) = \frac{1}{1 + e^{-x}} \]</div>
<p>[0, 1]</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/intro_70_0.png" src="../../_images/intro_70_0.png" />
</div>
</div>
</section>
<section id="vanishing-exploding-gradient">
<h2>vanishing/exploding gradient<a class="headerlink" href="#vanishing-exploding-gradient" title="Permalink to this headline">¶</a></h2>
<p>the sigmoid function saturates (i.e., produces
extreme valued outputs) very quickly and for a majority of the inputs. This can
become a problem because it can lead to the gradients becoming either zero or
diverging to an overflowing floating-point value. These phenomena are also
known as vanishing gradient problem and exploding gradient problem</p>
<p>As a consequence, it is rare to see sigmoid units used in neural
networks other than at the <strong>output</strong>, where the squashing property allows one to
interpret outputs as <strong>probabilities</strong></p>
</section>
<section id="tanh">
<h2>Tanh<a class="headerlink" href="#tanh" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[ f(x) = \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}} \]</div>
<p>[-1, 1]</p>
<p>maps the set of real values from (–∞, +∞) to
the range [-1, +1].</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/intro_75_0.png" src="../../_images/intro_75_0.png" />
</div>
</div>
</section>
<section id="relu">
<h2>Relu<a class="headerlink" href="#relu" title="Permalink to this headline">¶</a></h2>
<p>rectified linear unit<br />
clipping the negative values to zero,</p>
<div class="math notranslate nohighlight">
\[ f(x) = max(0, x) \]</div>
<p>[0, +inf]</p>
<p>The clipping effect of ReLU that helps with the <strong>vanishing gradient</strong> problem can
also become an issue, where over time certain outputs in the network can simply
become <strong>zero and never revive again</strong>. This is called the “dying ReLU” problem.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">relu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.</span><span class="p">,</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span><span class="n">y</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/intro_80_0.png" src="../../_images/intro_80_0.png" />
</div>
</div>
<p>To mitigate that effect, variants such as the <strong>Leaky ReLU</strong> and <strong>Parametric ReLU</strong>
(PReLU) activation functions have proposed, where the <strong>leak</strong> coefficient a is a
<strong>learned</strong> parameter.</p>
<div class="math notranslate nohighlight">
\[ f(x) = max(x, ax) \]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prelu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(</span><span class="n">num_parameters</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">prelu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="c1"># since y requires .grad so detach it to type cast numpy andavoid error</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/intro_83_0.png" src="../../_images/intro_83_0.png" />
</div>
</div>
</section>
<section id="softmax">
<h2>Softmax<a class="headerlink" href="#softmax" title="Permalink to this headline">¶</a></h2>
<p><img alt="" src="../../_images/softmax.png" /><br />
[0, 1]</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">y_output</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x_input</span><span class="p">)</span>
<span class="n">x_input</span>
<span class="n">y_output</span>
<span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># sum to one</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.4676, -0.8147, -0.5850]])
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.6148, 0.1706, 0.2146]])
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([1.])
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="loss-functions">
<h1>Loss Functions<a class="headerlink" href="#loss-functions" title="Permalink to this headline">¶</a></h1>
<section id="mean-squared-error-loss">
<h2>Mean Squared Error Loss<a class="headerlink" href="#mean-squared-error-loss" title="Permalink to this headline">¶</a></h2>
<p><img alt="" src="../../_images/mse.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mse_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">mse_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(1.3464, grad_fn=&lt;MseLossBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="categorical-cross-entropy-loss">
<h2>Categorical Cross-Entropy Loss<a class="headerlink" href="#categorical-cross-entropy-loss" title="Permalink to this headline">¶</a></h2>
<p><img alt="" src="../../_images/ccel.png" /></p>
<p>#note<br />
compute how <strong>different</strong> two <strong>distributions</strong> are.<br />
We want the probability of the
<strong>correct</strong> class to be <strong>close to 1</strong>, whereas the <strong>other</strong> classes have a probability <strong>close
to 0</strong>. <em><strong>Log(1) = 0</strong></em>
Product = sum of log</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ce_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">ce_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="n">outputs</span>
<span class="n">targets</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 1.3654, -0.6839, -1.2567,  0.6865, -0.1485],
        [ 1.6060, -1.1797,  0.6773, -0.0960, -0.3345],
        [ 0.5175, -0.5598, -0.3623, -0.0477,  0.8693]], requires_grad=True)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([1, 0, 3])
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(1.7233, grad_fn=&lt;NllLossBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>For above, a vector of random values is first used to simulate network
output. Then, the ground truth vector, called targets, is created as a vector of
integers because PyTorch’s implementation of CrossEntropyLoss() assumes
that each input has one particular <strong>class</strong>, and each class has a unique <strong>index</strong>. This
is why targets has <strong>three</strong> elements: an index representing the <strong>correct class</strong> for
each <strong>input</strong>. From this assumption, it performs the computationally more efficient
operation of indexing into the model output</p>
</section>
<section id="why-use-e-in-the-formula">
<h2>why use e in the formula?<a class="headerlink" href="#why-use-e-in-the-formula" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>There is a limit to how small or how large a number can be.</p></li>
<li><p>If input negative -&gt; log gives exponentially small number, if positive, exponentially large number.</p></li>
<li><p>Network’s output is assumed to be the vector just prior to applying the softmax
function</p></li>
<li><p>The log function is the inverse of the exponential function,
and log(exp(x)) is just equal to x.</p></li>
</ol>
<p><strong>Conclusion</strong><br />
mathematical simplifications are made assuming the <strong>exponential</strong>
function that is the <strong>core</strong> of the softmax function and the <strong>log</strong> function that is used
in the cross-entropy computations in order to be more numerically <strong>stable</strong> and
<strong>avoid</strong> really <strong>small</strong> or really <strong>large</strong> numbers (log property).</p>
</section>
<section id="binary-cross-entropy-loss">
<h2>Binary cross-entropy loss<a class="headerlink" href="#binary-cross-entropy-loss" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bce_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
<span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">probabilities</span>
<span class="n">targets</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">bce_loss</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.3914],
        [0.2337],
        [0.5652],
        [0.6740]], grad_fn=&lt;SigmoidBackward0&gt;)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[1.],
        [0.],
        [1.],
        [0.]])
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.3914],
        [0.2337],
        [0.5652],
        [0.6740]], grad_fn=&lt;SigmoidBackward0&gt;)
tensor(0.7239, grad_fn=&lt;BinaryCrossEntropyBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="supervised-training">
<h1>Supervised Training<a class="headerlink" href="#supervised-training" title="Permalink to this headline">¶</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>Supervised learning requires the following: a <strong>model</strong>, a
<strong>loss</strong> function, <strong>training</strong> data, and an <strong>optimization</strong> algorithm. The training data for
supervised learning is pairs of observations and targets; the model computes
predictions from the observations, and the loss measures the error of the
predictions as compared to the targets. The goal of the training is to use the
8
gradient-based optimization algorithm to adjust the model’s parameters so that
the losses are as low as possible.</p>
</section>
<section id="optimiser">
<h2>Optimiser<a class="headerlink" href="#optimiser" title="Permalink to this headline">¶</a></h2>
<p>While the model produces predictions and the loss function measures
the error between predictions and targets, the optimizer <strong>updates</strong> the <strong>weights</strong> of
the model using the <strong>error signal</strong>. In its simplest form, there is a single
hyperparameter that controls the update behavior of the optimizer. This
hyperparameter, called a learning rate, controls how much impact the error
signal has on updating the weights.</p>
</section>
<section id="instantiating-the-adam-optimizer">
<h2>Instantiating the Adam optimizer<a class="headerlink" href="#instantiating-the-adam-optimizer" title="Permalink to this headline">¶</a></h2>
<section id="gradient-descent-overview">
<h3>Gradient Descent overview<a class="headerlink" href="#gradient-descent-overview" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>any <strong>bookkeeping</strong> information, such as gradients, currently stored inside the model (perceptron) object is <strong>cleared</strong> with a function named zero_grad().</p></li>
<li><p>make <strong>prediction</strong>: the model computes outputs (y_pred) given the input data (x_data).</p></li>
<li><p>the <strong>loss</strong> is computed by comparing model outputs (y_pred) to intended targets (y_target).<br />
The PyTorch loss object (<strong>criterion</strong>) has a function named backward() that iteratively propagates the loss backward through the computational graph and notifies each parameter of its gradient.</p></li>
</ol>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="toy-example">
<h1>Toy Example<a class="headerlink" href="#toy-example" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://github.com/joosthub/PyTorchNLPBook/blob/master/chapters/chapter_3/Chapter-3-Diving-Deep-into-Supervised-Training.ipynb">https://github.com/joosthub/PyTorchNLPBook/blob/master/chapters/chapter_3/Chapter-3-Diving-Deep-into-Supervised-Training.ipynb</a></p>
<section id="perceptron">
<h2>Perceptron<a class="headerlink" href="#perceptron" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Perceptron</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; A Perceptron is one Linear layer &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            input_dim (int): size of the input features</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Perceptron</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The forward pass of the MLP</span>

<span class="sd">        Args:</span>
<span class="sd">            x_in (torch.Tensor): an input data tensor. </span>
<span class="sd">                x_in.shape should be (batch, input_dim)</span>
<span class="sd">        Returns:</span>
<span class="sd">            the resulting tensor. tensor.shape should be (batch, 1)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x_in</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training">
<h2>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">n_batches</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">seed</span> <span class="o">=</span> <span class="mi">1337</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">perceptron</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">input_dim</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">perceptron</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">bce_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>

<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">x_data_static</span><span class="p">,</span> <span class="n">y_truth_static</span> <span class="o">=</span> <span class="n">get_toy_data</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">visualize_results</span><span class="p">(</span><span class="n">perceptron</span><span class="p">,</span> <span class="n">x_data_static</span><span class="p">,</span> <span class="n">y_truth_static</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Initial Model State&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="c1">#plt.savefig(&#39;initial.png&#39;)</span>

<span class="n">change</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">last</span> <span class="o">=</span> <span class="mf">10.0</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="n">change</span> <span class="o">&gt;</span> <span class="n">epsilon</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="n">n_epochs</span> <span class="ow">or</span> <span class="n">last</span> <span class="o">&gt;</span> <span class="mf">0.3</span><span class="p">:</span>
<span class="c1">#for epoch in range(n_epochs):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span><span class="p">):</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">x_data</span><span class="p">,</span> <span class="n">y_target</span> <span class="o">=</span> <span class="n">get_toy_data</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">perceptron</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">bce_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_target</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        
        <span class="n">loss_value</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_value</span><span class="p">)</span>

        <span class="n">change</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">last</span> <span class="o">-</span> <span class="n">loss_value</span><span class="p">)</span>
        <span class="n">last</span> <span class="o">=</span> <span class="n">loss_value</span>
               
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
    <span class="n">visualize_results</span><span class="p">(</span><span class="n">perceptron</span><span class="p">,</span> <span class="n">x_data_static</span><span class="p">,</span> <span class="n">y_truth_static</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> 
                      <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">loss_value</span><span class="si">}</span><span class="s2">; </span><span class="si">{</span><span class="n">change</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">epoch</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1">#plt.savefig(&#39;epoch{}_toylearning.png&#39;.format(epoch))</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="vocab-vectoriser-dataloader">
<h1>Vocab, vectoriser, dataloader<a class="headerlink" href="#vocab-vectoriser-dataloader" title="Permalink to this headline">¶</a></h1>
<p>The <strong>Vocabulary</strong> coordinates the <strong>integer-to-token mappings</strong> that
we discussed in “Observation and Target Encoding”. We use a Vocabulary both
for mapping the text tokens to integers and for mapping the class labels to
integers. Next, the <strong>Vectorizer</strong> encapsulates the <strong>vocabularies</strong> and is responsible
for ingesting string data, like a review’s text, and <strong>converting</strong> it to numerical
<strong>vectors</strong> that will be used in the training routine. We use the final assisting class,
PyTorch’s <strong>DataLoader</strong>, to group and <strong>collate</strong> the individual vectorized data
points into <strong>minibatches</strong></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="the-yelp-review-dataset">
<h1>The Yelp Review Dataset<a class="headerlink" href="#the-yelp-review-dataset" title="Permalink to this headline">¶</a></h1>
<p>In 2015, Yelp held a contest in which it asked participants to predict the rating of
a restaurant given its review. Zhang, Zhao, and Lecun (2015) simplified the
dataset by converting the 1- and 2-star ratings into a “negative” sentiment class
and the 3- and 4-star ratings into a “positive” sentiment class, and split it into
560,000 training samples and 38,000 testing samples.</p>
<section id="note">
<h2>Note<a class="headerlink" href="#note" title="Permalink to this headline">¶</a></h2>
<p>we use a “light” version of the
dataset, which is derived by selecting 10% of the training samples as the full
dataset. This has two consequences. First, using a small dataset makes the
training–testing loop fast, so we can experiment quickly.</p>
<p>From this smaller subset, we split the dataset into three partitions: one for
training, one for validation, and one for testing.</p>
</section>
<section id="creating-training-validation-and-testing-splits">
<h2>Creating training, validation, and testing splits<a class="headerlink" href="#creating-training-validation-and-testing-splits" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split the subset by rating to create new train, val, and test splits</span>
<span class="n">by_rating</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">review_subset</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">by_rating</span><span class="p">[</span><span class="n">row</span><span class="o">.</span><span class="n">rating</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">to_dict</span><span class="p">())</span>
<span class="c1"># Create split data</span>
<span class="n">final_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">item_list</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">by_rating</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">item_libst</span><span class="p">)</span>
    <span class="n">n_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">item_list</span><span class="p">)</span>
    <span class="n">n_train</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train_proportion</span> <span class="o">*</span> <span class="n">n_total</span><span class="p">)</span>
    <span class="n">n_val</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">val_proportion</span> <span class="o">*</span> <span class="n">n_total</span><span class="p">)</span>
    <span class="n">n_test</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">test_proportion</span> <span class="o">*</span> <span class="n">n_total</span><span class="p">)</span>
    <span class="c1"># Give data point a split attribute</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">item_list</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]:</span>
    <span class="n">item</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">item_list</span><span class="p">[</span><span class="n">n_train</span><span class="p">:</span><span class="n">n_train</span><span class="o">+</span><span class="n">n_val</span><span class="p">]:</span>
    <span class="n">item</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;val&#39;</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">item_list</span><span class="p">[</span><span class="n">n_train</span><span class="o">+</span><span class="n">n_val</span><span class="p">:</span><span class="n">n_train</span><span class="o">+</span><span class="n">n_val</span><span class="o">+</span><span class="n">n_test</span><span class="p">]:</span>
    <span class="n">item</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;test&#39;</span>
    <span class="c1"># Add to final list</span>
    <span class="n">final_list</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">item_list</span><span class="p">)</span>
    <span class="n">final_reviews</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">final_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="minimally-cleaning-the-data">
<h2>Minimally cleaning the data<a class="headerlink" href="#minimally-cleaning-the-data" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">preprocess_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>

    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="c1"># adding whitespace around punctuation symbols: &#39;a!b&#39; =&gt; &#39;a ! b&#39;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;([.,!?])&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot; \1 &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="c1"># removing extraneous symbols that aren’t punctuation for all the splits</span>
    <span class="c1"># E.g. @ will be removed</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^a-zA-Z.,!?]+&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>
<span class="n">final_reviews</span><span class="o">.</span><span class="n">review</span> <span class="o">=</span> <span class="n">final_reviews</span><span class="o">.</span><span class="n">review</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">preprocess_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-vocabulary">
<h2>The Vocabulary<a class="headerlink" href="#the-vocabulary" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>from text to vectorized minibatch is to map each <strong>token</strong> to
a <strong>numerical</strong> version of itself.</p></li>
<li><p>The standard methodology is to have a <strong>bijection—a</strong>
mapping that can be reversed—between the tokens and integers. In Python, this is simply <strong>two</strong> <strong>dictionaries</strong>.</p></li>
<li><p>The Vocabulary class not only manages this
bijection—allowing the user to <strong>add new tokens</strong> and have the i<strong>ndex
autoincrement</strong>—but also handles a special token called UNK, which stands for <strong>“unknown</strong>.</p></li>
<li><p>we will even explicitly <strong>restrict</strong> <strong>infrequent</strong> tokens from our Vocabulary so that there are <strong>UNK</strong> tokens in our <strong>training</strong> routine</p></li>
</ul>
<hr class="docutils" />
<ul class="simple">
<li><p>add_token() is called to add new tokens to the Vocabulary, -</p></li>
<li><p>lookup_token() when retrieving the index for a token, and</p></li>
<li><p>lookup_index() when retrieving the token corresponding to a specific index.</p></li>
</ul>
<hr class="docutils" />
<p>The Vocabulary class <strong>maintains</strong> token to integer mapping needed
for the rest of the machine learning pipeline</p>
<section id="class-code">
<h3>Class code<a class="headerlink" href="#class-code" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Vocabulary</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Class to process text and extract vocabulary for mapping&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_to_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">add_unk</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unk_token</span><span class="o">=</span><span class="s2">&quot;&lt;UNK&gt;&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            token_to_idx (dict): a pre-existing map of tokens to indices</span>
<span class="sd">            add_unk (bool): a flag that indicates whether to add the UNK token</span>
<span class="sd">            unk_token (str): the UNK token to add into the Vocabulary</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">token_to_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">token_to_idx</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span> <span class="o">=</span> <span class="n">token_to_idx</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_token</span> <span class="o">=</span> <span class="p">{</span><span class="n">idx</span><span class="p">:</span> <span class="n">token</span> 
                              <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">_add_unk</span> <span class="o">=</span> <span class="n">add_unk</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_unk_token</span> <span class="o">=</span> <span class="n">unk_token</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">add_unk</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="n">unk_token</span><span class="p">)</span> 
        
        
    <span class="k">def</span> <span class="nf">to_serializable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; returns a dictionary that can be serialized &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;token_to_idx&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">,</span> 
                <span class="s1">&#39;add_unk&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_unk</span><span class="p">,</span> 
                <span class="s1">&#39;unk_token&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unk_token</span><span class="p">}</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_serializable</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">contents</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; instantiates the Vocabulary from a serialized dictionary &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">contents</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update mapping dicts based on the token.</span>

<span class="sd">        Args:</span>
<span class="sd">            token (str): the item to add into the Vocabulary</span>
<span class="sd">        Returns:</span>
<span class="sd">            index (int): the integer corresponding to the token</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">index</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_token</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">token</span>
        <span class="k">return</span> <span class="n">index</span>
    
    <span class="k">def</span> <span class="nf">add_many</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add a list of tokens into the Vocabulary</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            tokens (list): a list of string tokens</span>
<span class="sd">        Returns:</span>
<span class="sd">            indices (list): a list of indices corresponding to the tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">lookup_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieve the index associated with the token </span>
<span class="sd">          or the UNK index if token isn&#39;t present.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            token (str): the token to look up </span>
<span class="sd">        Returns:</span>
<span class="sd">            index (int): the index corresponding to the token</span>
<span class="sd">        Notes:</span>
<span class="sd">            `unk_index` needs to be &gt;=0 (having been added into the Vocabulary) </span>
<span class="sd">              for the UNK functionality </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">lookup_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the token associated with the index</span>
<span class="sd">        </span>
<span class="sd">        Args: </span>
<span class="sd">            index (int): the index to look up</span>
<span class="sd">        Returns:</span>
<span class="sd">            token (str): the token corresponding to the index</span>
<span class="sd">        Raises:</span>
<span class="sd">            KeyError: if the index is not in the Vocabulary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">index</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_token</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;the index (</span><span class="si">%d</span><span class="s2">) is not in the Vocabulary&quot;</span> <span class="o">%</span> <span class="n">index</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_token</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;Vocabulary(size=</span><span class="si">%d</span><span class="s2">)&gt;&quot;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="vectorizer-one-hot">
<h2>Vectorizer - One hot<a class="headerlink" href="#vectorizer-one-hot" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>second stage of going from a <strong>text</strong> dataset to a <strong>vectorized</strong> minibatch is to <strong>iterate</strong> through the tokens of an input data point and convert each token to its integer form</p></li>
<li><p>utilizes Python’s &#64;classmethod decorator for the method <strong>from_dataframe()</strong> to <strong>indicate</strong> an <strong>entry</strong> point to <strong>instantiating</strong> the Vectorizer</p></li>
<li><p>from_dataframe() iterates over the rows of a Pandas DataFrame with two goals.</p>
<ul>
<li><p>first goal is to <strong>count</strong> the <strong>frequency</strong> of all tokens present in
the dataset.</p></li>
<li><p>The second goal is to <strong>create</strong> a <strong>Vocabulary</strong> that only uses tokens that <strong>are</strong> as <strong>frequent</strong> as a provided keyword argument to the method, cutoff. Effectively, this method is finding <strong>all words</strong> that occur <strong>at least cutoff times</strong> and <strong>adding</strong> them to the <strong>Vocabulary</strong>.</p></li>
<li><p>Because the UNK token is also added to the Vocabulary, any <strong>words</strong> that are <strong>not added</strong> will have the <strong>unk_index</strong> when the Vocabulary’s <strong>lookup_token</strong>() method is called</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p>The method <strong>vectorize</strong>() encapsulates the core functionality of the
Vectorizer.</p>
<ul class="simple">
<li><p>It takes as an argument a string representing a review and returns a <strong>vectorized representation</strong> of the review.</p></li>
<li><p>one-hot representation is used below.</p></li>
<li><p>limitations.</p>
<ul>
<li><p>sparse—the number of unique words in the review will always be far less than the number of unique words in the Vocabulary</p></li>
<li><p>discards the order in which the words appeared in the review (the “bag of words” approach).</p></li>
</ul>
</li>
</ul>
<section id="id1">
<h3>Class code<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ReviewVectorizer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; The Vectorizer which coordinates the Vocabularies and puts them to use&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review_vocab</span><span class="p">,</span> <span class="n">rating_vocab</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            review_vocab (Vocabulary): maps words to integers</span>
<span class="sd">            rating_vocab (Vocabulary): maps class labels to integers</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span> <span class="o">=</span> <span class="n">review_vocab</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rating_vocab</span> <span class="o">=</span> <span class="n">rating_vocab</span>

    <span class="k">def</span> <span class="nf">vectorize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a collapsed one-hit vector for the review</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            review (str): the review </span>
<span class="sd">        Returns:</span>
<span class="sd">            one_hot (np.ndarray): the collapsed one-hot encoding </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">one_hot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">:</span>
                <span class="n">one_hot</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="o">.</span><span class="n">lookup_token</span><span class="p">(</span><span class="n">token</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">one_hot</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_dataframe</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">review_df</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mi">25</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Instantiate the vectorizer from the dataset dataframe</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            review_df (pandas.DataFrame): the review dataset</span>
<span class="sd">            cutoff (int): the parameter for frequency-based filtering</span>
<span class="sd">        Returns:</span>
<span class="sd">            an instance of the ReviewVectorizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">review_vocab</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="p">(</span><span class="n">add_unk</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">rating_vocab</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="p">(</span><span class="n">add_unk</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        <span class="c1"># Add ratings</span>
        <span class="k">for</span> <span class="n">rating</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">review_df</span><span class="o">.</span><span class="n">rating</span><span class="p">)):</span>
            <span class="n">rating_vocab</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="n">rating</span><span class="p">)</span>

        <span class="c1"># Add top words if count &gt; provided count</span>
        <span class="n">word_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">review_df</span><span class="o">.</span><span class="n">review</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">:</span>
                    <span class="n">word_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
               
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">word_counts</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="n">cutoff</span><span class="p">:</span>
                <span class="n">review_vocab</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">review_vocab</span><span class="p">,</span> <span class="n">rating_vocab</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_serializable</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">contents</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Instantiate a ReviewVectorizer from a serializable dictionary</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            contents (dict): the serializable dictionary</span>
<span class="sd">        Returns:</span>
<span class="sd">            an instance of the ReviewVectorizer class</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">review_vocab</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="o">.</span><span class="n">from_serializable</span><span class="p">(</span><span class="n">contents</span><span class="p">[</span><span class="s1">&#39;review_vocab&#39;</span><span class="p">])</span>
        <span class="n">rating_vocab</span> <span class="o">=</span>  <span class="n">Vocabulary</span><span class="o">.</span><span class="n">from_serializable</span><span class="p">(</span><span class="n">contents</span><span class="p">[</span><span class="s1">&#39;rating_vocab&#39;</span><span class="p">])</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">review_vocab</span><span class="o">=</span><span class="n">review_vocab</span><span class="p">,</span> <span class="n">rating_vocab</span><span class="o">=</span><span class="n">rating_vocab</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">to_serializable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create the serializable dictionary for caching</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            contents (dict): the serializable dictionary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;review_vocab&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">review_vocab</span><span class="o">.</span><span class="n">to_serializable</span><span class="p">(),</span>
                <span class="s1">&#39;rating_vocab&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">rating_vocab</span><span class="o">.</span><span class="n">to_serializable</span><span class="p">()}</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="a-pytorch-dataset-class">
<h2>A PyTorch Dataset class<a class="headerlink" href="#a-pytorch-dataset-class" title="Permalink to this headline">¶</a></h2>
<p>final stage of the text-to-vectorized-minibatch pipeline is to actually <strong>group</strong> the vectorized data points</p>
<ul class="simple">
<li><p>we wrap the DataLoader in a <strong>generate_batches</strong>() function, which is a generator to conveniently <strong>switch</strong> the data between the CPU and the GPU.</p></li>
</ul>
<p>Function</p>
<ul class="simple">
<li><p><strong>getitem</strong>()</p></li>
</ul>
<section id="id2">
<h3>Class code<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ReviewDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review_df</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            review_df (pandas.DataFrame): the dataset</span>
<span class="sd">            vectorizer (ReviewVectorizer): vectorizer instantiated from dataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">review_df</span> <span class="o">=</span> <span class="n">review_df</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">review_df</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">review_df</span><span class="o">.</span><span class="n">split</span><span class="o">==</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_df</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">val_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">review_df</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">review_df</span><span class="o">.</span><span class="n">split</span><span class="o">==</span><span class="s1">&#39;val&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_df</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">test_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">review_df</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">review_df</span><span class="o">.</span><span class="n">split</span><span class="o">==</span><span class="s1">&#39;test&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_df</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_lookup_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span><span class="p">),</span>
                             <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_size</span><span class="p">),</span>
                             <span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span><span class="p">)}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">load_dataset_and_make_vectorizer</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">review_csv</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load dataset and make a new vectorizer from scratch</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            review_csv (str): location of the dataset</span>
<span class="sd">        Returns:</span>
<span class="sd">            an instance of ReviewDataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">review_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">review_csv</span><span class="p">)</span>
        <span class="n">train_review_df</span> <span class="o">=</span> <span class="n">review_df</span><span class="p">[</span><span class="n">review_df</span><span class="o">.</span><span class="n">split</span><span class="o">==</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">review_df</span><span class="p">,</span> <span class="n">ReviewVectorizer</span><span class="o">.</span><span class="n">from_dataframe</span><span class="p">(</span><span class="n">train_review_df</span><span class="p">))</span>
    
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">load_dataset_and_load_vectorizer</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">review_csv</span><span class="p">,</span> <span class="n">vectorizer_filepath</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load dataset and the corresponding vectorizer. </span>
<span class="sd">        Used in the case in the vectorizer has been cached for re-use</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            review_csv (str): location of the dataset</span>
<span class="sd">            vectorizer_filepath (str): location of the saved vectorizer</span>
<span class="sd">        Returns:</span>
<span class="sd">            an instance of ReviewDataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">review_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">review_csv</span><span class="p">)</span>
        <span class="n">vectorizer</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">load_vectorizer_only</span><span class="p">(</span><span class="n">vectorizer_filepath</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">review_df</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">load_vectorizer_only</span><span class="p">(</span><span class="n">vectorizer_filepath</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;a static method for loading the vectorizer from file</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            vectorizer_filepath (str): the location of the serialized vectorizer</span>
<span class="sd">        Returns:</span>
<span class="sd">            an instance of ReviewVectorizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vectorizer_filepath</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ReviewVectorizer</span><span class="o">.</span><span class="n">from_serializable</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fp</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">save_vectorizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectorizer_filepath</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;saves the vectorizer to disk using json</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            vectorizer_filepath (str): the location to save the vectorizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vectorizer_filepath</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span><span class="o">.</span><span class="n">to_serializable</span><span class="p">(),</span> <span class="n">fp</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_vectorizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; returns the vectorizer &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span>

    <span class="k">def</span> <span class="nf">set_split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; selects the splits in the dataset using a column in the dataframe </span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            split (str): one of &quot;train&quot;, &quot;val&quot;, or &quot;test&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_target_split</span> <span class="o">=</span> <span class="n">split</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_target_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lookup_dict</span><span class="p">[</span><span class="n">split</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target_size</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;the primary entry point method for PyTorch datasets</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            index (int): the index to the data point </span>
<span class="sd">        Returns:</span>
<span class="sd">            a dictionary holding the data point&#39;s features (x_data) and label (y_target)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">row</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

        <span class="n">review_vector</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">review</span><span class="p">)</span>

        <span class="n">rating_index</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span><span class="o">.</span><span class="n">rating_vocab</span><span class="o">.</span><span class="n">lookup_token</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">rating</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;x_data&#39;</span><span class="p">:</span> <span class="n">review_vector</span><span class="p">,</span>
                <span class="s1">&#39;y_target&#39;</span><span class="p">:</span> <span class="n">rating_index</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">get_num_batches</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Given a batch size, return the number of batches in the dataset</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            batch_size (int)</span>
<span class="sd">        Returns:</span>
<span class="sd">            number of batches in the dataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>  
    
<span class="k">def</span> <span class="nf">generate_batches</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A generator function which wraps the PyTorch DataLoader. It will </span>
<span class="sd">      ensure each tensor is on the write device location.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">data_dict</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">out_data_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">out_data_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">out_data_dict</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="perceptron-classifier">
<h2>Perceptron Classifier<a class="headerlink" href="#perceptron-classifier" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>numerical stability issues with applying a sigmoid and then using this loss function.</p></li>
<li><p>Solution: use <strong>BCEWithLogitsLoss</strong>(), To use  this loss function, the output should not have the sigmoid function applied</p></li>
</ul>
<section id="id3">
<h3>Class code<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ReviewClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; a simple perceptron-based classifier &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_features</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">        num_features (int): the size of the input feature vector</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ReviewClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">num_features</span><span class="p">,</span>
        <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">,</span> <span class="n">apply_sigmoid</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The forward pass of the classifier</span>
<span class="sd">        Args:</span>
<span class="sd">        x_in (torch.Tensor): an input data tensor</span>
<span class="sd">        x_in.shape should be (batch, num_features)</span>
<span class="sd">        apply_sigmoid (bool): a flag for the sigmoid activation</span>
<span class="sd">        should be false if used with the cross-entropy losses</span>
<span class="sd">        Returns:</span>
<span class="sd">        the resulting tensor. tensor.shape should be (batch,).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x_in</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">apply_sigmoid</span><span class="p">:</span>
            <span class="n">y_out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y_out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y_out</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="training-route">
<h1>Training Route<a class="headerlink" href="#training-route" title="Permalink to this headline">¶</a></h1>
<section id="args-hyperparam-program-options">
<h2>args - hyperparam &amp; program options<a class="headerlink" href="#args-hyperparam-program-options" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="c1"># Data and path information</span>
    <span class="n">frequency_cutoff</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
    <span class="n">model_state_file</span><span class="o">=</span><span class="s1">&#39;model.pth&#39;</span><span class="p">,</span>
    <span class="n">review_csv</span><span class="o">=</span><span class="s1">&#39;data/yelp/reviews_with_splits_lite.csv&#39;</span><span class="p">,</span>
    <span class="n">save_dir</span><span class="o">=</span><span class="s1">&#39;model_storage/ch3/yelp/&#39;</span><span class="p">,</span>
    <span class="n">vectorizer_file</span><span class="o">=</span><span class="s1">&#39;vectorizer.json&#39;</span><span class="p">,</span>
    <span class="c1"># No model hyperparameters</span>
    <span class="c1"># Training hyperparameters</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">early_stopping_criteria</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1337</span><span class="p">,</span>
    <span class="c1"># Runtime options omitted for space</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="helper-initial-update-train-state">
<h2>Helper: Initial/update train state,<a class="headerlink" href="#helper-initial-update-train-state" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_train_state</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;epoch_index&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s1">&#39;train_acc&#39;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s1">&#39;val_acc&#39;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s1">&#39;test_loss&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
            <span class="s1">&#39;test_acc&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">}</span>
<span class="n">train_state</span> <span class="o">=</span> <span class="n">make_train_state</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">args</span><span class="o">.</span><span class="n">cuda</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">args</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">cuda</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="c1"># dataset and vectorizer</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ReviewDataset</span><span class="o">.</span><span class="n">load_dataset_and_make_vectorizer</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">review_csv</span><span class="p">)</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_vectorizer</span><span class="p">()</span>
<span class="c1"># model</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">ReviewClassifier</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">review_vocab</span><span class="p">))</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># loss and optimizer</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="bare-bones-training-loop">
<h2>bare-bones training loop<a class="headerlink" href="#bare-bones-training-loop" title="Permalink to this headline">¶</a></h2>
<p>an <strong>inner</strong> loop over minibatches in the dataset, and an <strong>outer</strong> loop, which repeats the inner loop a number of times.
In the inner loop, <strong>losses</strong> are computed for each <strong>minibatch</strong>, and the optimizer is used to update the model parameters.</p>
<hr class="docutils" />
<p>Given how we’ve constructed our dataset, the <strong>split</strong> should always be set <strong>before</strong> <strong>generate_batches</strong>() is called</p>
<hr class="docutils" />
<ul class="simple">
<li><p>The .eval() method makes the model parameters <strong>immutable</strong> and <strong>disables</strong> <strong>dropout</strong>.</p></li>
<li><p>disables computation of the <strong>loss</strong> and <strong>propagation</strong> of gradients back to the parameters</p>
<ul>
<li><p>This is important because we do not want the model <strong>adjusting</strong> its parameters relative to <strong>validation</strong> data. Instead, we want this data to serve as a measure of how well the model is performing.</p></li>
</ul>
</li>
</ul>
<section id="code">
<h3>code<a class="headerlink" href="#code" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">epoch_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;epoch_index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch_index</span>

    <span class="c1"># Iterate over training dataset</span>

    <span class="c1"># setup: batch generator, set loss and acc to 0, set train mode on</span>
    <span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">)</span> <span class="c1"># train for now, then to &#39;val&#39; later when we want to measure model performance at the end of the epoch</span>
    <span class="n">batch_generator</span> <span class="o">=</span> <span class="n">generate_batches</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> 
                                        <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> 
                                        <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">running_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="c1"># indicate that the model is in “training mode” and the model parameters are mutable</span>
    <span class="c1"># also enables regularization mechanisms like dropout</span>
    <span class="n">classifier</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> 
    
    <span class="k">for</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">batch_dict</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">):</span>
        <span class="c1"># the training routine is these 5 steps:</span>

        <span class="c1"># --------------------------------------</span>
        <span class="c1"># step 1. zero the gradients</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># step 2. compute the output</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">x_in</span><span class="o">=</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_data&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>

        <span class="c1"># step 3. compute the loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
        <span class="n">loss_t</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="p">(</span><span class="n">loss_t</span> <span class="o">-</span> <span class="n">running_loss</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># step 4. use loss to produce gradients</span>
        <span class="c1"># resulting in gradients being propagated to each parameter.</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># step 5. use optimizer to take gradient step</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># -----------------------------------------</span>
        <span class="c1"># compute the accuracy</span>
        <span class="n">acc_t</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">])</span>
        <span class="n">running_acc</span> <span class="o">+=</span> <span class="p">(</span><span class="n">acc_t</span> <span class="o">-</span> <span class="n">running_acc</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># update bar</span>
        <span class="n">train_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">running_loss</span><span class="p">,</span> 
                                <span class="n">acc</span><span class="o">=</span><span class="n">running_acc</span><span class="p">,</span> 
                                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch_index</span><span class="p">)</span>
        <span class="c1"># The training state is first updated with the final loss and accuracy values.</span>
        <span class="n">train_bar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span> 

    <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss</span><span class="p">)</span>
    <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;train_acc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="test-set">
<h2>Test set<a class="headerlink" href="#test-set" title="Permalink to this headline">¶</a></h2>
<p>Different between <strong>val</strong> &amp; <strong>test</strong>:</p>
<ul class="simple">
<li><p>the test set should be run as <strong>little</strong> as possible.</p></li>
<li><p>Each time you run a trained model on the test set, make a new model decision (such as changing the size of the layers), and remeasure the new retrained model on the test set, you are <strong>biasing</strong> your modeling decisions toward the <strong>test</strong> data.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="n">batch_generator</span> <span class="o">=</span> <span class="n">generate_batches</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">running_acc</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">for</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">batch_dict</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">):</span>
    <span class="c1"># compute the output</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">x_in</span><span class="o">=</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_data&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
    <span class="c1"># compute the loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
    <span class="n">loss_batch</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">running_loss</span> <span class="o">+=</span> <span class="p">(</span><span class="n">loss_batch</span> <span class="o">-</span> <span class="n">running_loss</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># compute the accuracy</span>
    <span class="n">acc_batch</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">])</span>
    <span class="n">running_acc</span> <span class="o">+=</span> <span class="p">(</span><span class="n">acc_batch</span> <span class="o">-</span> <span class="n">running_acc</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;test_loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">running_loss</span>
    <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;test_acc&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">running_acc</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="inference-printing-the-prediction">
<h2>Inference: Printing the prediction<a class="headerlink" href="#inference-printing-the-prediction" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_rating</span><span class="p">(</span><span class="n">review</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">,</span>
                    <span class="n">decision_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predict the rating of a review</span>
<span class="sd">    Args:</span>
<span class="sd">        review (str): the text of the review</span>
<span class="sd">        classifier (ReviewClassifier): the trained model</span>
<span class="sd">        vectorizer (ReviewVectorizer): the corresponding vectorizer</span>
<span class="sd">        decision_threshold (float): The numerical boundary which</span>
<span class="sd">                                    separates the rating classes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">review</span> <span class="o">=</span> <span class="n">preprocess_text</span><span class="p">(</span><span class="n">review</span><span class="p">)</span>
    <span class="n">vectorized_review</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">review</span><span class="p">))</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">vectorized_review</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">probability_value</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">index</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">probability_value</span> <span class="o">&lt;</span> <span class="n">decision_threshold</span><span class="p">:</span>
        <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">rating_vocab</span><span class="o">.</span><span class="n">lookup_index</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
<span class="n">test_review</span> <span class="o">=</span> <span class="s2">&quot;this is a pretty awesome book&quot;</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">predict_rating</span><span class="p">(</span><span class="n">test_review</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> -&gt; </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_review</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="inspecting-model-weights">
<h2>Inspecting model weights<a class="headerlink" href="#inspecting-model-weights" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sort weights</span>
<span class="n">fc1_weights</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">fc1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">_</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">fc1_weights</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="c1"># Top 20 words</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Influential words in Positive Reviews:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------------------------------&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">review_vocab</span><span class="o">.</span><span class="n">lookup_index</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    
    
<span class="sd">&quot;&quot;&quot; Oupput:</span>
<span class="sd">Influential words in Positive Reviews:</span>
<span class="sd">--------------------------------------</span>
<span class="sd">great</span>
<span class="sd">awesome</span>
<span class="sd">amazing</span>
<span class="sd">love</span>
<span class="sd">friendly</span>
<span class="sd">delicious</span>
<span class="sd">best</span>
<span class="sd">excellent</span>
<span class="sd">...</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Top 20 negative words</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Influential words in Negative Reviews:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------------------------------&quot;</span><span class="p">)</span>
<span class="n">indices</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">review_vocab</span><span class="o">.</span><span class="n">lookup_index</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

<span class="sd">&quot;&quot;&quot; output</span>
<span class="sd">Influential words in Negative Reviews:</span>
<span class="sd">--------------------------------------</span>
<span class="sd">worst</span>
<span class="sd">horrible</span>
<span class="sd">mediocre</span>
<span class="sd">terrible</span>
<span class="sd">not</span>
<span class="sd">rude</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="general-utilities-seed-mkdir">
<h2>General utilities: seed, mkdir<a class="headerlink" href="#general-utilities-seed-mkdir" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">set_seed_everywhere</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">cuda</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cuda</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">handle_dirs</span><span class="p">(</span><span class="n">dirpath</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dirpath</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dirpath</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="more">
<h1>More<a class="headerlink" href="#more" title="Permalink to this headline">¶</a></h1>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./unfinished/pytorch-nlp-bk"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="nlp-book.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">NLP Book</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="nn.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Feed-Forward Networks for NLP</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Jerry<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>