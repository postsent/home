{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "get_ipython().ast_node_interactivity = 'all'\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Supp code and exampels](https://github.com/joosthub/PyTorchNLPBookm) \n",
    "Perface > using code example: \"\"\n",
    "\n",
    "> “ Natural Language Processing with PyTorch by Delip Rao and Brian McMahan (O’Reilly). Copyright 2019, Delip Rao and Brian McMahan, 978-1-491-97823-8.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One bot / Binary encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1-1. Generating a “collapsed” one-hot or binary representation using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    " \n",
    "sentence1 = 'Time flies flies like an arrow.'\n",
    "sentence2 = 'Fruit flies like a banana.'\n",
    "corpus = [sentence1, sentence2]\n",
    "vocab = ['an', 'arrow', 'banana', 'flies', 'fruit', 'like', 'time']\n",
    "#note here a, an are treated as one word, so only an is shwon\n",
    "one_hot_vectorizer = CountVectorizer(binary=True)\n",
    "one_hot = one_hot_vectorizer.fit_transform(corpus).toarray()\n",
    "one_hot\n",
    "sns.heatmap(one_hot, annot=True,\n",
    "            cbar=False, xticklabels=vocab, # cbar is for the heat value illustartion\n",
    "            yticklabels=['Sentence 1', 'Sentence 2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF representation\n",
    "Example 1-2. Generating a TF-IDF representation using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    " \n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus).toarray()\n",
    "sns.heatmap(tfidf, annot=True, cbar=False, xticklabels=vocab,\n",
    "            yticklabels= ['Sentence 1', 'Sentence 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def p(t=''):\n",
    "    print('-------'+t+'-------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    \"\"\"summarise properties of a tensor x\n",
    "\n",
    "    Args:\n",
    "        x (tensor): \n",
    "    \"\"\"\n",
    "    print(\"Type: {}\".format(x.type()))\n",
    "    print(\"Shape/size: {}\".format(x.shape))\n",
    "    print(\"Values: \\n{}\".format(x))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.Tensor(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random normal dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.5866, 0.0962, 0.1946],\n",
      "        [0.3136, 0.0838, 0.3909]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[ 0.2589,  0.4765, -0.0993],\n",
      "        [-0.8002, -0.0610, -0.3848]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.rand(2, 3))   # uniform random\n",
    "describe(torch.randn(2, 3))  # random normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2, 3],  \n",
    "                 [4, 5, 6]])\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensfor from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.DoubleTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.9093, 0.7515, 0.5657],\n",
      "        [0.5321, 0.7644, 0.4786]], dtype=torch.float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "npy = np.random.rand(2, 3)\n",
    "describe(torch.from_numpy(npy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2, 3],  \n",
    "                    [4, 5, 6]])\n",
    "describe(x)\n",
    "\n",
    "x = x.long()\n",
    "describe(x)\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], \n",
    "                 [4, 5, 6]], dtype=torch.int64)\n",
    "describe(x)\n",
    "\n",
    "x = x.float() \n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randn, add, arange, view/reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------randn-------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5208, -0.1943,  0.2444],\n",
       "        [-0.1555, -0.2432, -0.8521]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------add-------\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-1.0416, -0.3887,  0.4888],\n",
      "        [-0.3111, -0.4865, -1.7041]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-1.0416, -0.3887,  0.4888],\n",
      "        [-0.3111, -0.4865, -1.7041]])\n",
      "\n",
      "-------arange-------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------view/reshape-------\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "-------sum-------\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3])\n",
      "Values: \n",
      "tensor([3, 5, 7])\n",
      "\n",
      "-------transpose-------\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p('randn')\n",
    "x = torch.randn(2, 3)\n",
    "x\n",
    "\n",
    "p('add')\n",
    "describe(torch.add(x, x))\n",
    "describe(x + x)\n",
    "\n",
    "p('arange')\n",
    "x = torch.arange(6)\n",
    "x\n",
    "\n",
    "p('view/reshape')\n",
    "\n",
    "x = x.view(2, 3)\n",
    "describe(x)\n",
    "\n",
    "p('sum')\n",
    "describe(torch.sum(x, dim=0))\n",
    "\n",
    "p('transpose')\n",
    "\n",
    "describe(torch.transpose(x, 0, 1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing and indexing a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([1, 2])\n",
      "Values: \n",
      "tensor([[0, 1]])\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).view(2, 3)\n",
    "describe(x)\n",
    "\n",
    "describe(x[:1, :2]) # row 0, first two cols\n",
    "\n",
    "describe(x[0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex indexing: noncontiguous indexing of a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[0, 2],\n",
      "        [3, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# indices = torch.LongTensor([0, 2]) \n",
    "indices = torch.tensor([0,2])\n",
    "describe(torch.index_select(x, dim=1, index=indices)) # 0, 2th col only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### particular row + col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------particular row col elements-------\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2])\n",
      "Values: \n",
      "tensor([0, 4])\n",
      "\n",
      "-------cat based rows-------\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([4, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "-------stack-------\n",
      "\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 2, 3])\n",
      "Values: \n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x\n",
    "p()\n",
    "row_indices = torch.arange(2).long()\n",
    "row_indices\n",
    "p()\n",
    "col_indices = torch.LongTensor([0, 1])\n",
    "col_indices\n",
    "p('particular row col elements')\n",
    "describe(x[row_indices, col_indices]) # row0,col0 +  row1,col1\n",
    "p('cat based rows')\n",
    "describe(torch.cat([x, x], dim=0))\n",
    "p('stack') # stack another depth, depth: 2, row: 2, col: 2\n",
    "describe(torch.stack([x, x]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear algebra: add, multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.ones(3, 2)\n",
    "x2\n",
    "x2[:, 1] += 1 # all row, col 1\n",
    "describe(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mm, type must be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[ 3.,  6.],\n",
      "        [12., 24.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.arange(6).view(2, 3).float()\n",
    "describe(x1)\n",
    "describe(x2)\n",
    "\n",
    "describe(torch.mm(x1, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and Computational Graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tensors for gradient bookkeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "describe(x)\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requires_grad   \n",
    "\n",
    "\"When you create a tensor with requires_grad=True, you are requiring PyTorch to manage **bookkeeping** information that computes gradients. \n",
    "First, PyTorch will keep track of the values of the **forward pass**. Then, at the end of the computations, a single **scalar** is used to compute a backward pass. The **backward pass** is initiated by using the backward() method on a tensor resulting from the evaluation of a loss function. The backward pass computes a gradient value for a tensor object that participated in the forward pass.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[21., 21.],\n",
      "        [21., 21.]], grad_fn=<AddBackward0>)\n",
      "\n",
      "False\n",
      "--------------\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      "21.0\n",
      "\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "y = (x + 2) * (x + 5) + 3\n",
    "describe(y)\n",
    "print(x.grad is None)\n",
    "\n",
    "p()\n",
    "\n",
    "z = y.mean()\n",
    "describe(z)\n",
    "z.backward()\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the gradient is a value that represents the **slope** of a function output with respect to the **function input**\n",
    "**Optimizers** use the .grad variable to **update** the values of the **parameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Tensors\n",
    "- To use a GPU, you need to first allocate the tensor on the GPU’s memory\n",
    "- Before it is run on CPU.\n",
    "- The CUDA API was created by **NVIDIA** and is limited to use on only **NVIDIA GPUs**\n",
    "\n",
    "Transfering the tensor from the CPU to the GPU while maintaining its underlying type. The preferred method in PyTorch is to be device agnostic and write code that works whether it’s on the GPU or the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (torch.cuda.is_available())\n",
    "\n",
    "# preferred method: device agnostic tensor instantiation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)\n",
    "\n",
    "torch.zeros(1).cuda()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04c2c190d8d0e7e5e1678786cf96c5fe54de7e069d5117ea2521e84529e5d561"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
